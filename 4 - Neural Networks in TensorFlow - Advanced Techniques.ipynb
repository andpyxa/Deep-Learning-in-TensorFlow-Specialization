{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://firebasestorage.googleapis.com/v0/b/deep-learning-crash-course.appspot.com/o/Logo.png?alt=media&token=06318ee3-d7a0-44a0-97ae-2c95f110e3ac\" width=\"100\" height=\"100\" align=\"right\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Neural Networks in TensorFlow - Advanced Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://firebasestorage.googleapis.com/v0/b/deep-learning-crash-course.appspot.com/o/3Sup%2C%20Unsup%2C%20Rein.png?alt=media&token=4baee322-267b-4aab-b7b9-101b2c88685e\" width=\"800\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Sequential Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://firebasestorage.googleapis.com/v0/b/deep-learning-crash-course.appspot.com/o/1Keras.png?alt=media&token=9f4add09-14d3-49ed-bc11-f0497f6e96f1\" width=\"200\" height=\"200\" align=\"right\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">**Keras is a simple tool for constructing a neural network. It is a high-level API of TensorFlow 2:**</font> \n",
    "\n",
    "> <font size=\"3\">**an approachable, highly-productive interface for solving machine learning problems, with a focus on modern deep learning.**</font>\n",
    "\n",
    "<font size=\"3\">**The core data structures of Keras are layers and models.**</font>\n",
    "\n",
    "> <font size=\"3\">**The simplest type of model is the <span style=\"color:#4285F4\">Sequential model</span>, a linear stack of layers.**</font>\n",
    "\n",
    "> <font size=\"3\">**For more complex architectures, the Keras <span style=\"color:#4285F4\">Functional API</span> should be used, which allows to build arbitrary graphs of layers, or write models entirely from scratch.**</font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='Orange'>*Sequential model - When to use*</font>\n",
    "\n",
    "<font size=\"3\">**A Sequential model is appropriate for**</font> \n",
    "> <font size=\"3\">**<span style=\"color:#4285F4\">a plain stack of layers</span> where each layer has <span style=\"color:#4285F4\">exactly one input tensor and one output tensor</span>.**</font> \n",
    "\n",
    "<font size=\"3\">**This is not appropriate when:**</font> \n",
    "\n",
    "> <font size=\"3\">**Your model has <span style=\"color:#4285F4\">multiple inputs or multiple outputs</span>**</font> <br>\n",
    "> <font size=\"3\">**Any of your layers has <span style=\"color:#4285F4\">multiple inputs or multiple outputs</span>**</font> <br>\n",
    "> <font size=\"3\">**You need to do <span style=\"color:#4285F4\">layer sharing</span>**</font><br>\n",
    "> <font size=\"3\">**You want <span style=\"color:#4285F4\">non-linear topology</span> (e.g. a residual connection, a multi-branch model)**</font>\n",
    "\n",
    "Reference: https://keras.io/guides/sequential_model/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='Orange'>*Sequential model - How to use*</font>\n",
    "\n",
    "<font size=\"3\">**You can create a <span style=\"color:#4285F4\">Sequential model</span> by**</font> \n",
    "> <font size=\"3\">**Passing a list of layers to a Sequential constructor**</font> \n",
    "\n",
    "> <font size=\"3\">**<span style=\"background-color: #ECECEC; color:#0047bb\">.add()</span> method to incrementally setup layers**</font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='#176BEF'> Examples </font>\n",
    "<hr style=\"border:2px solid #E1F6FF\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://firebasestorage.googleapis.com/v0/b/deep-learning-crash-course.appspot.com/o/3NN9.png?alt=media&token=664be587-f0fe-43ec-8217-5ca7779ca0dd\" width=\"350\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = Sequential(\n",
    "    [\n",
    "        Dense(2, activation='relu', input_shape=(3,)),\n",
    "        Dense(1, activation='sigmoid'),\n",
    "    ]\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(2, activation='relu', input_shape=(3,)))\n",
    "model.add(Dense(1, activation ='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid #E1F6FF\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='Orange'>*Sequential model - Separated Activation Layer*</font>\n",
    "\n",
    "<font size=\"3\">**Keras also allows users to add <span style=\"color:#4285F4\">Activation layer</span> separately.**</font>\n",
    "\n",
    "<font size=\"3\">**The models and functions are always the same. The only difference is the architecture.**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='#176BEF'> Examples </font>\n",
    "<hr style=\"border:2px solid #E1F6FF\"> </hr>\n",
    "<img src=\"https://firebasestorage.googleapis.com/v0/b/deep-learning-crash-course.appspot.com/o/3NN9.png?alt=media&token=664be587-f0fe-43ec-8217-5ca7779ca0dd\" width=\"100\" align=\"right\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential(\n",
    "    [\n",
    "        Dense(2, input_shape=(3,)),\n",
    "        Activation('relu'),\n",
    "        Dense(1), \n",
    "        Activation('sigmoid'),\n",
    "    ]\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(2, input_shape=(3,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid #E1F6FF\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">**Activation function**</font>\n",
    "\n",
    "><font size=\"3\">**An activation function helps decide whether a neuron should be activated or not. That means it will help decide whether the neuron’s input to the network is important or not in the process of prediction using simpler mathematical operations.**</font>\n",
    "\n",
    "><font size=\"3\">**Therefore, the key role of an activation function is to <span style=\"color:#4285F4\">derive output from a set of input values</span> fed to a node (or a layer).**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Sequential Model - Attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='Orange'> Attributes of Layers</font>\n",
    "\n",
    "<font size=\"3\">**Layers are the basic building blocks of neural networks. A layer consists of**</font>\n",
    "> <font size=\"3\">**<span style=\"color:#4285F4\">Tensor-in tensor-out computation function</span> - which performs a logic defined in the <span style=\"background-color: #ECECEC; color:#0047bb\">call()</span> of applying the layer to the input tensors and returns output tensors**</font>\n",
    "\n",
    "> <font size=\"3\">**<span style=\"color:#4285F4\">State</span> - which represents the weights of the layers and is updated when the layer receives data during training, and stored in <span style=\"background-color: #ECECEC; color:#0047bb\">layer.weights</span>**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='#176BEF'> Examples </font>\n",
    "<hr style=\"border:2px solid #E1F6FF\"> </hr>\n",
    "<img src=\"https://firebasestorage.googleapis.com/v0/b/deep-learning-crash-course.appspot.com/o/3NN9.png?alt=media&token=664be587-f0fe-43ec-8217-5ca7779ca0dd\" width=\"100\" align=\"right\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(2, activation='relu', input_shape=(3,)))\n",
    "model.add(Dense(1, activation ='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">**A <span style=\"background-color: #ECECEC; color:#0047bb\">layers</span> instance is callable, much like a function. It returns a list containing the information of**</font>\n",
    "><font size=\"3\">**Layer's name**</font>\n",
    "\n",
    "><font size=\"3\">**Layer's address**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://firebasestorage.googleapis.com/v0/b/deep-learning-crash-course.appspot.com/o/4NNTechniques1.png?alt=media&token=41b1d525-1299-4634-a8ac-8eb128a4936c\" width=\"550\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">**Since it is a list, indexing is allowable.**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"This is the first layer's address:\", model.layers[0])\n",
    "print(\"This is the second layer's address:\", model.layers[1])\n",
    "\n",
    "print(\"This is the first layer's name:\", model.layers[0].name)\n",
    "print(\"This is the second layer's name:\", model.layers[1].name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">**Layers can be renamed by adding an argument <span style=\"color:#4285F4\">name</span>.**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(2, activation='relu', input_shape=(3,), name='First_Layer'))\n",
    "model.add(Dense(1, activation ='sigmoid',  name='Second_Layer'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"This is the first layer's name:\", model.layers[0].name)\n",
    "print(\"This is the second layer's name:\", model.layers[1].name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">**Layers can be retrieved with the use of <span style=\"background-color: #ECECEC; color:#0047bb\">get_layer()</span> function.**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Using INDEX to retrieve layer\", model.get_layer(index=0))\n",
    "\n",
    "print(\"Using NAME to retrieve layer\", model.get_layer(name='First_Layer'))\n",
    "print(\"Using NAME to retrieve layer\", model.get_layer('First_Layer'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid #E1F6FF\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='Orange'> Attributes of Inputs and Outputs</font>\n",
    "\n",
    "<font size=\"3\">**<span style=\"color:#4285F4\">Model</span> groups layers into an object for training and inference features. Besides hidden layer, there are two specific layers:**</font>\n",
    "> <font size=\"3\">**<span style=\"color:#4285F4\">Input Layer</span> - which serves as an entry point into a neural network and is callable by <span style=\"background-color: #ECECEC; color:#0047bb\">.inputs</span>**</font>\n",
    "\n",
    "> <font size=\"3\">**<span style=\"color:#4285F4\">Output Layer</span> - which serves as an exit point of a neural network and is callable by <span style=\"background-color: #ECECEC; color:#0047bb\">.outputs</span>**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='#176BEF'> Examples </font>\n",
    "<hr style=\"border:2px solid #E1F6FF\"> </hr>\n",
    "<img src=\"https://firebasestorage.googleapis.com/v0/b/deep-learning-crash-course.appspot.com/o/3NN9.png?alt=media&token=664be587-f0fe-43ec-8217-5ca7779ca0dd\" width=\"100\" align=\"right\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://firebasestorage.googleapis.com/v0/b/deep-learning-crash-course.appspot.com/o/4NNTechniques2.png?alt=media&token=b1191dbc-411c-46c3-a16f-f3b0db892108\" width=\"600\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid #E1F6FF\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\"><span style=\"background-color:#EA4335; color:white\">&nbsp;!&nbsp;</span></font>\n",
    "<font size=\"3\">**<span style=\"background-color: #ECECEC; color:#0047bb\">.add()</span> method can be used to incrementally setup layers, starting from first layer. There is also a corresponding <span style=\"background-color: #ECECEC; color:#0047bb\">.pop()</span> method to remove layers, starting from last layer.**</font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='#176BEF'> Examples </font>\n",
    "<hr style=\"border:2px solid #E1F6FF\"> </hr>\n",
    "<img src=\"https://firebasestorage.googleapis.com/v0/b/deep-learning-crash-course.appspot.com/o/3NN9.png?alt=media&token=664be587-f0fe-43ec-8217-5ca7779ca0dd\" width=\"100\" align=\"right\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"No. of layers:\", len(model.layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.pop()\n",
    "print(\"No. of layers:\", len(model.layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(1, activation ='sigmoid',  name='Second_Layer'))\n",
    "print(\"No. of layers:\", len(model.layers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid #E1F6FF\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Sequential Model - Save and load models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='Orange'>Whole-model saving & loading</font>\n",
    "<font size=\"3\">**Model can be saved completely to a single file. It will include:**</font>\n",
    "> <font size=\"3\">**The model's architecture/config**</font><br>\n",
    "\n",
    "> <font size=\"3\">**The model's weight values (which were learned during training)**</font><br>\n",
    "\n",
    "> <font size=\"3\">**The model's compilation information, if <span style=\"background-color: #ECECEC; color:#0047bb\">.compile()</span> is called**</font><br>\n",
    "\n",
    "> <font size=\"3\">**The optimizer and its state (this enables users to restart training)**</font><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='Orange'>APIs</font>\n",
    "<font size=\"3\">**There are two formats you can use to save an entire model to disk:**</font><br>\n",
    "> <font size=\"3\">**the <span style=\"color:#4285F4\">TensorFlow SavedModel format</span>**</font>\n",
    "\n",
    "> <font size=\"3\">**the older <span style=\"color:#4285F4\">Keras H5 format</span>**</font>\n",
    "\n",
    "<font size=\"3\">**<span style=\"color:#4285F4\">SavedModel</span> is the recommended format. It is the more comprehensive save format that saves the model architecture, weights, and the traced Tensorflow subgraphs of the call functions. This enables Keras to restore both built-in layers as well as custom objects.**</font><br>\n",
    "\n",
    "<font size=\"3\">**There are two APIs that can be used to save the models:**</font><br>\n",
    "> <font size=\"3\">**<span style=\"background-color: #ECECEC; color:#0047bb\">model.save()</span>**</font>\n",
    "    \n",
    "> <font size=\"3\">**<span style=\"background-color: #ECECEC; color:#0047bb\">tf.keras.models.save_model()</span>**</font>\n",
    "\n",
    "<font size=\"3\">**By default, the API saves model in <span style=\"color:#4285F4\">SavedModel format</span> when <span style=\"background-color: #ECECEC; color:#0047bb\">model.save()</span> is used. In that case, to switch to <span style=\"color:#4285F4\">Keras H5 format</span>, either:**</font> <br>\n",
    "\n",
    "> <font size=\"3\">**Passing <span style=\"background-color: #ECECEC; color:#0047bb\">save_format='h5'</span> to <span style=\"background-color: #ECECEC; color:#0047bb\">.save()</span>; or**</font>\n",
    "    \n",
    "> <font size=\"3\">**Passing a filename that ends in <span style=\"background-color: #ECECEC; color:#0047bb\">.h5</span> or <span style=\"background-color: #ECECEC; color:#0047bb\">.keras</span> to <span style=\"background-color: #ECECEC; color:#0047bb\">.save()</span>**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: https://www.tensorflow.org/guide/keras/save_and_serialize#:~:text=There%20are%20two%20formats%20you,you%20use%20model.save()%20."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='#176BEF'> Examples </font>\n",
    "<hr style=\"border:2px solid #E1F6FF\"> </hr>\n",
    "<img src=\"https://firebasestorage.googleapis.com/v0/b/deep-learning-crash-course.appspot.com/o/3NN9.png?alt=media&token=664be587-f0fe-43ec-8217-5ca7779ca0dd\" width=\"100\" align=\"right\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.random((100, 3))\n",
    "y = np.random.random((100, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(2, activation='relu', input_shape=(3,)))\n",
    "model.add(Dense(1, activation ='sigmoid'))\n",
    "model.compile(optimizer=\"adam\", loss=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">**Calling <span style=\"background-color: #ECECEC; color:#0047bb\">model.save()</span> creates a folder named my_model and saves model in <span style=\"color:#4285F4\">SavedModel format</span>**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">**It creates two folders and one file:**</font>\n",
    "\n",
    "> <font size=\"3\">**<span style=\"color:#4285F4\">assets</span> - which stores arbitrary files, called assets, that are needed for TensorFlow graph**</font>\n",
    "\n",
    "> <font size=\"3\">**<span style=\"color:#4285F4\">variables</span> - which stores weights**</font>\n",
    "\n",
    "> <font size=\"3\">**<span style=\"color:#4285F4\">saved_model.pb</span> - which stores the model architecture, and training configuration (including the optimizer, losses, and metrics)**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "for f in glob.glob(os.path.abspath(os.getcwd())+'\\\\my_model\\\\*'):\n",
    "    print(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">**Once the model is saved, <span style=\"background-color: #ECECEC; color:#0047bb\">load_model()</span> can be used to reconstruct the model identically.**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "reconstructed_model = load_model(\"my_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">**The reconstructed model is already compiled and has retained the weights, model architecture and training configuration, so training can resume:**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='#176BEF'> Examples </font>\n",
    "<hr style=\"border:2px solid #E1F6FF\"> </hr>\n",
    "<img src=\"https://firebasestorage.googleapis.com/v0/b/deep-learning-crash-course.appspot.com/o/3NN9.png?alt=media&token=664be587-f0fe-43ec-8217-5ca7779ca0dd\" width=\"100\" align=\"right\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.random((100, 3))\n",
    "y = np.random.random((100, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(2, activation='relu', input_shape=(3,)))\n",
    "model.add(Dense(1, activation ='sigmoid'))\n",
    "model.compile(optimizer=\"adam\", loss=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">**Keras also supports saving a single <span style=\"color:#4285F4\">HDF5</span> file which is a light-weight alternative to <span style=\"color:#4285F4\">SavedModel format</span>.**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_model_hdf5.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">**It creates only one file:**</font>\n",
    "\n",
    "> <font size=\"3\">**<span style=\"color:#4285F4\">h5</span> - which contains the model's architecture, weights values, and <span style=\"background-color: #ECECEC; color:#0047bb\">compile()</span> information**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "for f in glob.glob(os.path.abspath(os.getcwd())+'\\\\*.h5'):\n",
    "    print(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">**Similar to <span style=\"color:#4285F4\">SavedModel format</span>, once the model is saved, <span style=\"background-color: #ECECEC; color:#0047bb\">load_model()</span> can be used to reconstruct the model identically.**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "reconstructed_model_h5 = load_model(\"my_model_hdf5.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">**The reconstructed model is already compiled and has retained the weights, model architecture and training configuration, so training can resume:**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_model_h5.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">**Limitations**</font>\n",
    "><font size=\"3\">**Compared to the <span style=\"color:#4285F4\">SavedModel format</span>, there are two things that don't get included in the <span style=\"color:#4285F4\">H5</span> file: 1) <span style=\"color:#4285F4\">External losses & metrics</span> and 2) <span style=\"color:#4285F4\">Computation graph of custom objects</span>**</font>\n",
    "\n",
    "Reference: https://www.tensorflow.org/guide/keras/save_and_serialize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Sequential Model - Compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">**<span style=\"background-color: #ECECEC; color:#0047bb\">.compile()</span> allows for different arguments. It is used to configure the model for training. The most important arguments are:**</font>\n",
    "\n",
    ">> <font size=\"3\">**1<sup>st</sup> argument: <span style=\"color:#4285F4\">Optimizer</span>**</font><br>\n",
    "<br>\n",
    ">> <font size=\"3\">**2<sup>nd</sup> argument: <span style=\"color:#4285F4\">Loss function</span>**</font><br>\n",
    "<br>\n",
    ">> <font size=\"3\">**3<sup>rd</sup> argument: <span style=\"color:#4285F4\">Metrics</span>**</font>\n",
    "\n",
    "<img src=\"https://firebasestorage.googleapis.com/v0/b/deep-learning-crash-course.appspot.com/o/3NN10.png?alt=media&token=9223446e-8108-4082-b9c9-225018f9f54e\" width=\"550\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">**<span style=\"color:#4285F4\">Loss Function</span>**</font>\n",
    "> <font size=\"3\">**Once the neural network architecture is setup and added into the Sequential model object, samples are <span style=\"color:#4285F4\">foward propagated</span> and the corresponding estimates, $\\hat{y}$ are calculated.**</font><br>\n",
    "\n",
    "> <font size=\"3\">**<span style=\"color:#4285F4\">Loss function</span> is then applied to estimate the <span style=\"color:#4285F4\">loss values</span> between the true values (i.e. Labels, y) and predicted values (i.e. Estimates, $\\hat{y}$).**</font>\n",
    "\n",
    "<font size=\"3\">**<span style=\"color:#4285F4\">Optimizer</span>**</font>\n",
    "> <font size=\"3\">**Based on the <span style=\"color:#4285F4\">loss values</span>, <span style=\"color:#4285F4\">optimizer backward propagates</span> and calculates the <span style=\"color:#4285F4\">gradients</span> w.r.t weights, W and bias, b.**</font>\n",
    "\n",
    "><font size=\"3\">**The training will be stopped either when:**</font>\n",
    ">> <font size=\"3\">**The maximum number of epochs in <span style=\"background-color: #ECECEC; color:#0047bb\">.fit()</span> function is reached; OR**</font><br>\n",
    ">> <font size=\"3\">**A monitored quantity <span style=\"background-color: #ECECEC; color:#0047bb\">.EarlyStopping()</span> function has stopped improving.**</font>\n",
    "\n",
    "<font size=\"3\">**<span style=\"color:#4285F4\">Metrics</span>**</font>\n",
    "> <font size=\"3\">**A metric is an addition evaluation function that is used to judge the performance of the model**</font>\n",
    "\n",
    "> <font size=\"3\">**Metric functions are similar to loss functions, except that the results from evaluating a metric are not used when training the model. Therefore, any loss function can also be used as a metric**</font>\n",
    "\n",
    "> <font size=\"3\">**The main reason is because it is difficult to judge the performance based on loass values, such as mean squared error (MSE) and root mean squared error (RMSE). Therefore, sometimes, an extra metric, such as accuracy and mean absolute error (MAE), is used for additional evaluation.**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid #34A853\"> </hr>\n",
    "\n",
    "### <font color='#34A853'> Frequently Used Optimizers </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">**Almost all popular optimizers in deep learning are based on <span style=\"color:#4285F4\">gradient descent</span> which estimates the slope of a given <span style=\"color:#4285F4\">loss function</span> and update the parameters  towards a supposed global minimum.**</font>\n",
    "\n",
    "<font size=\"3\">**There are three different types of <span style=\"color:#4285F4\">gradient descent</span>:**</font>\n",
    "><font size=\"3\">**Batch Gradient Descent or Vanilla Gradient Descent** - The <span style=\"color:#4285F4\">entire dataset</span> are used to compute the gradient of the cost function for each iteration of the <span style=\"color:#4285F4\">gradient descent</span> and then update the parameters.</font>\n",
    "\n",
    "><font size=\"3\">**Stochastic Gradient Descent** - A <span style=\"color:#4285F4\">single sample</span> is randomly picked and used to compute the gradient of the cost function for each iteration of the <span style=\"color:#4285F4\">gradient descent</span> and then update the parameters.</font>\n",
    "\n",
    "><font size=\"3\">**Mini batch Gradient Descent** - This is a variation of stochastic gradient descent. A <span style=\"color:#4285F4\">mini batch of samples</span> is randomly picked and used to compute the gradient of the cost function for each iteration of the <span style=\"color:#4285F4\">gradient descent</span> and then update the parameters.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">**Let's denote by**</font>\n",
    "><font size=\"3\">**<span style=\"color:#4285F4\">w</span> the parameters**</font><br>\n",
    "><font size=\"3\">**<span style=\"color:#4285F4\">g</span> the gradients**</font><br>\n",
    "><font size=\"3\">**<span style=\"color:#4285F4\">α</span> the global learning rate**</font><br>\n",
    "><font size=\"3\">**<span style=\"color:#4285F4\">t</span> the time step**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='Orange'>*Stochastic Gradient Descent (SGD)*</font>\n",
    "\n",
    "<font size=\"3\">**In Keras, <span style=\"background-color: #ECECEC; color:#0047bb\">.SGD()</span> function is applying <span style=\"color:#4285F4\">mini batch gradient descent</span>. The optimizer estimates the direction of steepest descent based on <span style=\"color:#4285F4\">batch_size</span> defined in <span style=\"background-color: #ECECEC; color:#0047bb\">.fit()</span> function and takes a step in this direction. Since the step size is fixed, SGD can quickly get stuck on plateaus or in local minima.**</font>\n",
    "\n",
    "<font size=\"3\">***Update Rule:***</font> <img src=\"https://firebasestorage.googleapis.com/v0/b/deep-learning-crash-course.appspot.com/o/4NNEquation1.png?alt=media&token=7f9515ce-1817-48ac-9354-3a088ff06ad4\" width=\"550\" align=\"center\" style=\"float: middle\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='Orange'>*SGD with Momentum*</font>\n",
    "\n",
    "<font size=\"3\">**With <span style=\"color:#4285F4\">momentum</span>, SGD accelerates in directions of constant descent. The acceleration is defined by <span style=\"color:#4285F4\">momentum term β, $<$ 1</span>, which helps  the model escape plateaus and makes it less susceptible to getting stuck in local minima.**</font>\n",
    "    \n",
    "<font size=\"3\">***Update Rule:***</font> <img src=\"https://firebasestorage.googleapis.com/v0/b/deep-learning-crash-course.appspot.com/o/4NNEquation2.png?alt=media&token=cd5b2bbc-987d-4a02-8dbb-be4b35f9443b\" width=\"550\" align=\"center\" style=\"float: middle\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\"><span style=\"background-color:#EA4335; color:white\">&nbsp;!&nbsp;</span></font>\n",
    "<font size=\"3\">**In Keras, <span style=\"background-color: #ECECEC; color:#0047bb\">.SGD()</span> functions combine SGD without and with Momentum. When <span style=\"color:#4285F4\">momentum</span> is larger than 0, <span style=\"background-color: #ECECEC; color:#0047bb\">.SGD()</span> functions will update gradients with velocity equation.**</font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='Orange'>*AdaGrad*</font>\n",
    "\n",
    "<font size=\"3\">**The challenge of using <span style=\"color:#4285F4\">learning rate α</span> is that their hyperparameters have to be defined in advance and they depend heavily on the type of model and problem. Another problem is that the same learning rate is applied to all parameter updates. If data is sparse, it is better to be updated the parameters at different rates.**</font>\n",
    "    \n",
    "<font size=\"3\">**AdaGrad makes use of <span style=\"color:#4285F4\">adaptive learning</span> rates to address the problem. It scales the <span style=\"color:#4285F4\">learning rate α</span> for each parameter based on the square root of the inverse sum of the squared gradients. This method scales sparse gradient direction up which allows for larger steps in such directions, and results a faster convergence in problems with sparse features.**</font>\n",
    "\n",
    "<font size=\"3\">***Update Rule:***</font> <img src=\"https://firebasestorage.googleapis.com/v0/b/deep-learning-crash-course.appspot.com/o/4NNEquation3.png?alt=media&token=8766e128-1da2-4499-b91f-2b183c7e9b06\" width=\"550\" align=\"center\" style=\"float: middle\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='Orange'>*RMSprop*</font>\n",
    "\n",
    "<font size=\"3\">**Adagrad's main problem is its accumulation of the squared gradients in the denominator. The accumulated sum keeps growing during training. This in turn causes the learning rate to shrink and eventually become infinitesimally small, at which point the algorithm is no longer able to acquire additional knowledge.**</font>\n",
    "    \n",
    "<font size=\"3\">**To solve the radically diminishing learning rates, RMSprop scales the gradient in a less aggressive way. Instead of taking the <span style=\"color:#4285F4\">sum of squared gradients</span>, it takes a <span style=\"color:#4285F4\">moving average of the squared gradients</span>.**</font>\n",
    "\n",
    "<font size=\"3\">**RMSprop is often combined with <span style=\"color:#4285F4\">momentum</span> which helps the model escape plateaus and makes it less susceptible to getting stuck in local minima.**</font>\n",
    "\n",
    "<font size=\"3\">***Update Rule:***</font> <img src=\"https://firebasestorage.googleapis.com/v0/b/deep-learning-crash-course.appspot.com/o/4NNEquation4.png?alt=media&token=609c4197-3dae-447d-a6c9-aea9d754ff24\" width=\"550\" align=\"center\" style=\"float: middle\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='Orange'>*Adam*</font>\n",
    "\n",
    "<font size=\"3\">**Adaptive Moment Estimation (Adam) combines AdaGrad, RMSprop and momentum methods into one.**</font>\n",
    "    \n",
    "<font size=\"3\">**The direction of the step is determined by a <span style=\"color:#4285F4\">moving average of the gradients</span> and the step size is approximately upper bounded by the global step size. Furthermore, each dimension of the gradient is rescaled similar to RMSprop.**</font>\n",
    "    \n",
    "<font size=\"3\">**One key difference between Adam and RMSprop/AdaGrad is that the moment estimates m and v are corrected for their bias towards zero. Adam is well-known for achieving good performance with little hyper-parameter tuning.**</font>\n",
    "\n",
    "<font size=\"3\">***Update Rule:***</font> <img src=\"https://firebasestorage.googleapis.com/v0/b/deep-learning-crash-course.appspot.com/o/4NNEquation5.png?alt=media&token=62cfa064-f228-4d7d-8692-fa2385a712c0\" width=\"550\" align=\"center\" style=\"float: middle\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='#34A853'> Which optimizer to use? </font>\n",
    "\n",
    "><font size=\"3\">**As a rule of thumb, if input data is <span style=\"color:#4285F4\">sparse</span>, then using one of the <span style=\"color:#4285F4\">adaptive learning-rate</span> methods is likely to provide a better result.**</font>\n",
    "\n",
    "><font size=\"3\">**However, if you have the <span style=\"color:#4285F4\">resources</span> to find a good learning rate schedule, <span style=\"color:#4285F4\">SGD with momentum</span> is a solid choice.**</font>\n",
    "\n",
    "><font size=\"3\">**<span style=\"color:#4285F4\">RMSprop</span> is an extension of <span style=\"color:#4285F4\">AdaGrad</span> that deals with its <span style=\"color:#4285F4\">radically diminishing learning rates</span>. Therefore, in general, RMSprop is a better choice.**</font>\n",
    "    \n",
    "><font size=\"3\">**<span style=\"color:#4285F4\">Adam</span> adds <span style=\"color:#4285F4\">bias-correction and momentum</span> to RMSprop. Its bias-correction helps Adam slightly outperform RMSprop towards the end of optimization as gradients become sparser. Insofar, Adam might be the best overall choice.**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References:<br>\n",
    "https://www.lightly.ai/post/which-optimizer-should-i-use-for-my-machine-learning-project<br>\n",
    "https://towardsdatascience.com/learning-rate-schedules-and-adaptive-learning-rate-methods-for-deep-learning-2c8f433990d1<br>\n",
    "https://ruder.io/optimizing-gradient-descent/index.html#adagrad\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid #34A853\"> </hr>\n",
    "\n",
    "### <font color='#34A853'> Frequently Used Loss Functions </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">**The purpose of loss functions is to compute the quantity that a model should seek to minimize during training.**</font>\n",
    "\n",
    "<font size=\"3\">**There are three major categories of loss functions:**</font>\n",
    "\n",
    "><font size=\"3\">**<span style=\"color:#4285F4\">Probabilistic Losses</span>**</font>\n",
    "\n",
    "><font size=\"3\">**<span style=\"color:#4285F4\">Regression Losses</span>**</font>\n",
    "\n",
    "><font size=\"3\">**<span style=\"color:#4285F4\">Hinge Losses for \"maximum-margine\" classification</span>**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='Orange'>*Probabilistic Losses - Binary Crossentropy*</font>\n",
    "\n",
    "<font size=\"3\">**<span style=\"color:#4285F4\">Binary Crossentropy</span> computes the crossentropy loss between true labels and predicted labels.**</font>\n",
    "\n",
    "<font size=\"3\">**It is recommended to use this crossentropy function for <span style=\"color:#4285F4\">binary (0 or 1) classification problem</span>. The loss function requires the following inputs:**</font>\n",
    "\n",
    "><font size=\"3\">**<span style=\"color:#4285F4\">y_true</span> (true label): This is either 0 or 1.**</font>\n",
    "\n",
    "><font size=\"3\">**<span style=\"color:#4285F4\">y_pred</span> (predicted value): This is the model's prediction which either represents**</font> \n",
    ">><font size=\"3\">**a <span style=\"color:#4285F4\">logit</span> (i.e, value in [-inf, inf] when <span style=\"background-color: #ECECEC; color:#0047bb\">from_logits=True</span>), or**</font><br>\n",
    ">><font size=\"3\">**a <span style=\"color:#4285F4\">probability</span> (i.e, value in [0., 1.] when <span style=\"background-color: #ECECEC; color:#0047bb\">from_logits=False</span>).**</font>\n",
    "\n",
    "<font size=\"5\"><span style=\"background-color:#EA4335; color:white\">&nbsp;!&nbsp;</span></font> <font size=\"3\">**It is always recommended to apply <span style=\"background-color: #ECECEC; color:#0047bb\">from_logits=True</span>**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='Orange'>*Probabilistic Losses - Categorical Crossentropy & Sparse CategoricalCrossentropy*</font>\n",
    "\n",
    "<font size=\"3\">**<span style=\"color:#4285F4\">Categorical Crossentropy</span> and <span style=\"color:#4285F4\">SparseCategoricalCrossentropy</span> compute the crossentropy loss between true labels and predicted labels.**</font>\n",
    "\n",
    "<font size=\"3\">**It is recommended to use this crossentropy function for <span style=\"color:#4285F4\">two or more classes classification problem</span>.**</font> \n",
    "\n",
    "<font size=\"3\">**Both loss functions compute categorical crossentropy. The only difference is in how the labels are encoded.**</font>\n",
    "\n",
    "> <font size=\"3\">**For <span style=\"color:#4285F4\">one hot</span> representation, <span style=\"color:#4285F4\">CatergoricalCrossentropy</span> can be used.**</font>\n",
    "\n",
    "> <font size=\"3\">**For labels as integers (i.e. 0, 1, 2), <span style=\"color:#4285F4\">SparseCategoricalCrossentropy</span> can be used.**</font>\n",
    "\n",
    "<img src=\"https://firebasestorage.googleapis.com/v0/b/deep-learning-crash-course.appspot.com/o/4NNLossFunction.png?alt=media&token=8ad3c091-9925-43de-adb4-07b87f9e572a\" width=\"700\" align=\"center\" style=\"float: middle\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='Orange'>*Regression Losses - Mean Squared Error*</font>\n",
    "\n",
    "<font size=\"3\">**<span style=\"color:#4285F4\">Mean Squared Error</span> computes the mean of squares of errors between true labels and predicted labels.**</font>\n",
    "\n",
    "<font size=\"3\">**It is recommended to use this function for <span style=\"color:#4285F4\">regression problem</span>. The loss function is simply:**</font>\n",
    "\n",
    "><font size=\"3\">**<span style=\"color:#4285F4\">loss = (y_true - y_pred)<sup>2</sup></span>**</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='Orange'>*Regression Losses - Mean Absolute Error*</font>\n",
    "\n",
    "<font size=\"3\">**<span style=\"color:#4285F4\">Mean Absolute Error</span> computes the mean of absolute difference between true labels and predicted labels.**</font>\n",
    "\n",
    "<font size=\"3\">**<span style=\"color:#4285F4\">MAE</span> is very often applied in <span style=\"color:#4285F4\">metrics</span>, rather than <span style=\"color:#4285F4\">loss function</span>. If applied, it is used for <span style=\"color:#4285F4\">regression problem</span>. The loss function is:**</font>\n",
    "\n",
    "><font size=\"3\">**<span style=\"color:#4285F4\">loss = abs(y_true - y_pred)</span>**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='Orange'>*Regression Losses - Mean Absolute Percentage Error*</font>\n",
    "\n",
    "<font size=\"3\">**<span style=\"color:#4285F4\">Mean Absolute Percentage Error</span> computes the mean absolute percentage error between true labels and predicted labels.**</font>\n",
    "\n",
    "<font size=\"3\">**<span style=\"color:#4285F4\">MAPE</span> is also very often applied in <span style=\"color:#4285F4\">metrics</span>, rather than <span style=\"color:#4285F4\">loss function</span>. If applied, it is used for <span style=\"color:#4285F4\">regression problem</span>. The loss function is:**</font>\n",
    "\n",
    "><font size=\"3\">**<span style=\"color:#4285F4\">loss = 100 * abs(y_true - y_pred) / y_true</span>**</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='#34A853'> Which loss function to use? </font>\n",
    "\n",
    "<font size=\"3\">**The <span style=\"color:#4285F4\">output layer's activation function</span> determines the <span style=\"color:#4285F4\">output values</span>, while the <span style=\"color:#4285F4\">loss function</span> evaluates the <span style=\"color:#4285F4\">loss values</span> based on the difference between the output values and labels.**</font> \n",
    "    \n",
    "<font size=\"3\">**Therefore, it is always important to combine the <span style=\"color:#4285F4\">output layer's activation function</span> and <span style=\"color:#4285F4\">loss function</span> according to the <span style=\"color:#4285F4\">problem type</span> .**</font>\n",
    "\n",
    "<img src=\"https://firebasestorage.googleapis.com/v0/b/deep-learning-crash-course.appspot.com/o/3NN11.png?alt=media&token=9d57d341-c9ad-4126-918e-526bde571a1b\" width=\"950\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='#34A853'> How to create custom losses? </font>\n",
    "\n",
    "<font size=\"3\">**Keras allows to create custom losses. Any callable that returns an array of losses can be passed to <span style=\"background-color: #ECECEC; color:#0047bb\">compile()</span> as a loss.**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='#176BEF'> Examples </font>\n",
    "<hr style=\"border:2px solid #E1F6FF\"> </hr>\n",
    "<img src=\"https://firebasestorage.googleapis.com/v0/b/deep-learning-crash-course.appspot.com/o/3NN9.png?alt=media&token=664be587-f0fe-43ec-8217-5ca7779ca0dd\" width=\"100\" align=\"right\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.random((100, 3))\n",
    "y = np.random.random((100, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(2, activation='relu', input_shape=(3,)))\n",
    "model.add(Dense(1, activation ='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">**A custom loss function can be created by defining a function that takes the true values and predicted values as required parameters. The function should return an array of losses.**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss_function(y_true, y_pred):\n",
    "    squared_difference = tf.square(y_true - y_pred)\n",
    "    return tf.reduce_mean(squared_difference, axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">**The function can then be passed to <span style=\"background-color: #ECECEC; color:#0047bb\">compile()</span> as a loss.**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss=custom_loss_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">**Here is just a comparison between the <span style=\"color:#4285F4\">custom MSE</span> and <span style=\"color:#4285F4\">built-in MSE</span>.**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References:<br>\n",
    "https://analyticsindiamag.com/ultimate-guide-to-loss-functions-in-tensorflow-keras-api-with-python-implementation/<br>\n",
    "https://keras.io/api/losses/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid #34A853\"> </hr>\n",
    "\n",
    "### <font color='#34A853'> Frequently Used Metrics </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">**To compile a model, a <span style=\"color:#4285F4\">loss function</span> and an <span style=\"color:#4285F4\">optimizer</span> are needed to be specified. Optionally, some <span style=\"color:#4285F4\">metrics</span> can also be specified to judge the performance of a model.**</font>\n",
    "\n",
    "<font size=\"3\">**<span style=\"color:#4285F4\">Metric functions</span>  are similar to <span style=\"color:#4285F4\">loss functions</span>, except that the results from evaluating a metric are not used when training the model.**</font>\n",
    "\n",
    "<font size=\"3\">**There are six categories of metrics:**</font>\n",
    "\n",
    "><font size=\"3\">**<span style=\"color:#4285F4\">Accuracy metrics</span>**</font>\n",
    "\n",
    "><font size=\"3\">**<span style=\"color:#4285F4\">Probabilistic metrics</span>**</font>\n",
    "\n",
    "><font size=\"3\">**<span style=\"color:#4285F4\">Regression metrics</span>**</font>\n",
    "\n",
    "><font size=\"3\">**<span style=\"color:#4285F4\">Classification metrics based on True/False positives & negatives</span>**</font>\n",
    "\n",
    "><font size=\"3\">**<span style=\"color:#4285F4\">Image segmentation metrics</span>**</font>\n",
    "\n",
    "><font size=\"3\">**<span style=\"color:#4285F4\">Hinge metrics for \"maximum-margin\" classification</span>**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='Orange'>*Accuracy metrics - Accuracy*</font>\n",
    "\n",
    "<font size=\"3\">**<span style=\"color:#4285F4\">Accuracy</span> calculates how often predictions equal <span style=\"color:#4285F4\">labels</span>.**</font>\n",
    "\n",
    "<font size=\"3\">**This metric creates two local variables, <span style=\"color:#4285F4\">total</span> and <span style=\"color:#4285F4\">count</span> that are used to compute the <span style=\"color:#4285F4\">frequency</span> with which <span style=\"color:#4285F4\">y_pred</span> matches <span style=\"color:#4285F4\">y_true</span>.**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.array([[0],[0],[1],[1],[1]]) \n",
    "\n",
    "y_pred = np.array([[0.0],[0.2],[0.4],[0.95],[1.0]]) \n",
    "\n",
    "metric = tf.keras.metrics.Accuracy()\n",
    "metric.update_state(y_true, y_pred)\n",
    "\n",
    "print('Accuracy:', round(metric.result().numpy()*100), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='Orange'>*Accuracy metrics - Binary Accuracy*</font>\n",
    "\n",
    "<font size=\"3\">**<span style=\"color:#4285F4\">Binary accuracy</span> calculates how often predictions match <span style=\"color:#4285F4\">binary labels</span>.**</font>\n",
    "\n",
    "<font size=\"3\">**This metric creates two local variables, <span style=\"color:#4285F4\">total</span> and <span style=\"color:#4285F4\">count</span> that are used to compute the <span style=\"color:#4285F4\">frequency</span> with which <span style=\"color:#4285F4\">y_pred</span> matches <span style=\"color:#4285F4\">y_true</span>.**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.array([[0],[0],[1],[1],[1]]) \n",
    "\n",
    "y_pred = np.array([[0.0],[0.2],[0.4],[0.95],[1.0]]) \n",
    "\n",
    "metric = tf.keras.metrics.BinaryAccuracy()\n",
    "metric.update_state(y_true, y_pred)\n",
    "\n",
    "print('Accuracy:', round(metric.result().numpy()*100), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">**By default, <span style=\"color:#4285F4\">threshold</span> of <span style=\"background-color: #ECECEC; color:#0047bb\">BinaryAccuracy()</span> is <span style=\"color:#4285F4\">0.5</span>, i.e.**</font>\n",
    "\n",
    "><font size=\"3\">**If <span style=\"color:#4285F4\">y_pred</span> $>$ <span style=\"color:#4285F4\">0.5</span>, set value to 1.0**</font>\n",
    "\n",
    "><font size=\"3\">**If <span style=\"color:#4285F4\">y_pred</span> $<$ <span style=\"color:#4285F4\">0.5</span>, set value to 0.0**</font>\n",
    "\n",
    "<font size=\"3\">**Therefore, in the example, <span style=\"color:#4285F4\">y_pred</span> becomes**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.array([[0.0],[0.0],[0.0],[1.0],[1.0]])\n",
    "\n",
    "metric = tf.keras.metrics.BinaryAccuracy()\n",
    "metric.update_state(y_true, y_pred)\n",
    "\n",
    "print('Accuracy:', round(metric.result().numpy()*100), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='Orange'>*Accuracy metrics - Categorical Accuracy*</font>\n",
    "\n",
    "<font size=\"3\">**<span style=\"color:#4285F4\">Categorical accuracy</span> calculates how often predictions match <span style=\"color:#4285F4\">one hot labels</span>.**</font>\n",
    "\n",
    "<font size=\"3\">**This metric creates two local variables, <span style=\"color:#4285F4\">total</span> and <span style=\"color:#4285F4\">count</span> that are used to compute the <span style=\"color:#4285F4\">frequency</span> with which <span style=\"color:#4285F4\">y_pred</span> matches <span style=\"color:#4285F4\">y_true</span>.**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.array([[0,   0,   0,   0,   1],\n",
    "                   [0,   0,   0,   1,   0],\n",
    "                   [0,   0,   1,   0,   0],\n",
    "                   [0,   1,   0,   0,   0],\n",
    "                   [1,   0,   0,   0,   0]]) \n",
    "\n",
    "y_pred = np.array([[0,   0,   0,   1,   0],\n",
    "                   [0,   0,   0,   1,   0],\n",
    "                   [0.1, 0.2, 0.6, 0.0, 0.1],\n",
    "                   [0.1, 0.9, 0,   0,   0],\n",
    "                   [0.5, 0.2, 0.1, 0.1, 0.1]]) \n",
    "\n",
    "metric = tf.keras.metrics.CategoricalAccuracy()\n",
    "metric.update_state(y_true, y_pred)\n",
    "\n",
    "print('Accuracy:', round(metric.result().numpy()*100), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">**The calculation involves two steps:**</font>\n",
    "\n",
    "><font size=\"3\">**1) An index at which the <span style=\"color:#4285F4\">maxiumum value</span> occurs will be identified with the use of <span style=\"background-color: #ECECEC; color:#0047bb\">argmax()</span>.**</font>\n",
    "\n",
    "><font size=\"3\">**2) If it is the same for both <span style=\"color:#4285F4\">y_pred</span> and <span style=\"color:#4285F4\">y_true</span>, it is considered accurate.**</font>\n",
    "\n",
    "<font size=\"3\">**The logic is like:**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_maxpo = np.argmax(y_true, axis=1)\n",
    "\n",
    "print(y_true_maxpo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_maxpo = np.argmax(y_pred, axis=1)\n",
    "\n",
    "print(y_pred_maxpo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Accuracy = sum(y_true_maxpo==y_pred_maxpo)/len(y_pred_maxpo)*100\n",
    "\n",
    "print('Accuracy:', Accuracy, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='Orange'>*Accuracy metrics - Sparse Categorical Accuracy*</font>\n",
    "\n",
    "<font size=\"3\">**<span style=\"color:#4285F4\">Sparse Categorical accuracy</span> calculates how often predictions match <span style=\"color:#4285F4\">integer labels</span>.**</font>\n",
    "\n",
    "<font size=\"3\">**This metric creates two local variables, <span style=\"color:#4285F4\">total</span> and <span style=\"color:#4285F4\">count</span> that are used to compute the <span style=\"color:#4285F4\">frequency</span> with which <span style=\"color:#4285F4\">y_pred</span> matches <span style=\"color:#4285F4\">y_true</span>.**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.array([[0],\n",
    "                   [1],\n",
    "                   [2],\n",
    "                   [3]]) \n",
    "\n",
    "y_pred = np.array([[1,   0,   0,   0],\n",
    "                   [0,   0,   0,   1],\n",
    "                   [0.1, 0.2, 0.7, 0.0],\n",
    "                   [0.1, 0.0, 0.0, 0.9]]) \n",
    "\n",
    "metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "metric.update_state(y_true, y_pred)\n",
    "\n",
    "print('Accuracy:', round(metric.result().numpy()*100), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">**The calculation involves two steps:**</font>\n",
    "\n",
    "><font size=\"3\">**1) An index at which the <span style=\"color:#4285F4\">maxiumum value in y_pred</span> occurs will be identified with the use of <span style=\"background-color: #ECECEC; color:#0047bb\">argmax()</span>.**</font>\n",
    "\n",
    "><font size=\"3\">**2) If the index is same as <span style=\"color:#4285F4\">y_true</span>, it is considered accurate.**</font>\n",
    "\n",
    "<font size=\"3\">**The logic is like:**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_maxpo = np.argmax(y_pred, axis=1)\n",
    "\n",
    "print(y_pred_maxpo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_integer = y_true.flatten()\n",
    "\n",
    "print(y_true_integer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Accuracy = sum(y_true_integer==y_pred_maxpo)/len(y_pred_maxpo)*100\n",
    "\n",
    "print('Accuracy:', Accuracy, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='Orange'>*Accuracy metrics - TopK Categorical Accuracy*</font>\n",
    "\n",
    "<font size=\"3\">**<span style=\"color:#4285F4\">TopK Categorical accuracy</span> calculates how often <span style=\"color:#4285F4\">one hot targets</span> are in the top <span style=\"color:#4285F4\">K predictions</span>.**</font>\n",
    "\n",
    "><font size=\"3\">**<span style=\"color:#4285F4\">y_pred</span> is firstly ranked in the descending order of probability values.**</font>\n",
    "\n",
    "><font size=\"3\">**If <span style=\"color:#4285F4\">y_pred</span> present in the <span style=\"color:#4285F4\">index of non-zero y_true</span> is less than or equal to K, it is considered accurate.**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.array([[0,   0,   0,   0,   1],\n",
    "                   [0,   0,   0,   1,   0],\n",
    "                   [0,   0,   1,   0,   0],\n",
    "                   [0,   1,   0,   0,   0],\n",
    "                   [1,   0,   0,   0,   0]]) \n",
    "\n",
    "y_pred = np.array([[0,   0,   0,   1,   0],\n",
    "                   [0,   0,   0,   1,   0],\n",
    "                   [0.1, 0.6, 0.3, 0.0, 0.1],\n",
    "                   [0.1, 0.9, 0,   0,   0],\n",
    "                   [0.2, 0.4, 0.3, 0, 0.1]]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kTop=1\n",
    "\n",
    "metric = tf.keras.metrics.TopKCategoricalAccuracy(k=kTop)\n",
    "metric.update_state(y_true,y_pred)\n",
    "\n",
    "print('Accuracy:', round(metric.result().numpy()*100), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kTop=2\n",
    "\n",
    "metric = tf.keras.metrics.TopKCategoricalAccuracy(k=kTop)\n",
    "metric.update_state(y_true,y_pred)\n",
    "\n",
    "print('Accuracy:', round(metric.result().numpy()*100), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kTop=3\n",
    "\n",
    "metric = tf.keras.metrics.TopKCategoricalAccuracy(k=kTop)\n",
    "metric.update_state(y_true,y_pred)\n",
    "\n",
    "print('Accuracy:', round(metric.result().numpy()*100), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">**The logic is like:**</font>\n",
    "\n",
    "><font size=\"3\">**1) Rank the predictions**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import rankdata\n",
    "\n",
    "rankpos = lambda x : (len(x)+1) - rankdata(x).astype(int)\n",
    "y_pred_rank = np.array([rankpos(row) for row in y_pred])\n",
    "\n",
    "print(y_pred_rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "><font size=\"3\">**2) Identify the <span style=\"color:#4285F4\">index of non-zero y_true</span>**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_y_true = y_true == 1\n",
    "\n",
    "print(index_y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "><font size=\"3\">**3) Identify the ranks according to the <span style=\"color:#4285F4\">index of non-zero y_true</span>**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_pred_rank = y_pred_rank[index_y_true]\n",
    "\n",
    "print(y_true_pred_rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "><font size=\"3\">**4) Assign K value as thershold**</font><br>\n",
    "><font size=\"3\">**5) Count how many ranks are higher than the K value and calculate the accuracy**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kTop = 1\n",
    "\n",
    "Accuracy = np.sum(y_true_pred_rank <= kTop)/len(y_true_pred_rank)*100\n",
    "\n",
    "print('Accuracy:', Accuracy, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kTop = 2\n",
    "\n",
    "Accuracy = np.sum(y_true_pred_rank <= kTop)/len(y_true_pred_rank)*100\n",
    "\n",
    "print('Accuracy:', Accuracy, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kTop = 3\n",
    "\n",
    "Accuracy = np.sum(y_true_pred_rank <= kTop)/len(y_true_pred_rank)*100\n",
    "\n",
    "print('Accuracy:', Accuracy, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='Orange'>*Accuracy metrics - Sparse TopK Categorical Accuracy*</font>\n",
    "\n",
    "<font size=\"3\">**<span style=\"color:#4285F4\">Sparse TopK Categorical accuracy</span> calculates how often <span style=\"color:#4285F4\">integer targets</span> are in the top <span style=\"color:#4285F4\">K predictions</span>.**</font>\n",
    "\n",
    "><font size=\"3\">**<span style=\"color:#4285F4\">y_pred</span> is firstly ranked in the descending order of probability values.**</font>\n",
    "\n",
    "><font size=\"3\">**If <span style=\"color:#4285F4\">y_pred</span> present in the <span style=\"color:#4285F4\">index of non-zero y_true</span> is less than or equal to K, it is considered accurate.**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.array([[0],\n",
    "                   [1],\n",
    "                   [2],\n",
    "                   [3]]) \n",
    "\n",
    "y_pred = np.array([[1,   0,   0,   0],\n",
    "                   [0.1, 0,   0.1, 0.8],\n",
    "                   [0.1, 0.6, 0.3, 0.0],\n",
    "                   [0.1, 0.3, 0.4, 0.2]]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kTop=1\n",
    "\n",
    "metric = tf.keras.metrics.SparseTopKCategoricalAccuracy(k=kTop)\n",
    "metric.update_state(y_true, y_pred)\n",
    "\n",
    "print('Accuracy:', round(metric.result().numpy()*100), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kTop=2\n",
    "\n",
    "metric = tf.keras.metrics.SparseTopKCategoricalAccuracy(k=kTop)\n",
    "metric.update_state(y_true, y_pred)\n",
    "\n",
    "print('Accuracy:', round(metric.result().numpy()*100), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kTop=3\n",
    "\n",
    "metric = tf.keras.metrics.SparseTopKCategoricalAccuracy(k=kTop)\n",
    "metric.update_state(y_true, y_pred)\n",
    "\n",
    "print('Accuracy:', round(metric.result().numpy()*100), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">**The logic is like:**</font>\n",
    "\n",
    "><font size=\"3\">**1) Rank the predictions**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import rankdata\n",
    "\n",
    "rankpos = lambda x : (len(x)+1) - rankdata(x).astype(int)\n",
    "y_pred_rank = np.array([rankpos(row) for row in y_pred])\n",
    "\n",
    "print(y_pred_rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "><font size=\"3\">**2) Identify the <span style=\"color:#4285F4\">index of non-zero y_true</span>**</font><Br>\n",
    "><font size=\"3\">**3) Identify the ranks according to the <span style=\"color:#4285F4\">index of non-zero y_true</span>**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_pred_rank = y_true.astype(int)\n",
    "\n",
    "for i in range(len(y_true)):\n",
    "     y_true_pred_rank[i] = y_pred_rank[i,y_true[i]]\n",
    "\n",
    "print(y_true_pred_rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "><font size=\"3\">**4) Assign K value as thershold**</font><br>\n",
    "><font size=\"3\">**5) Count how many ranks are higher than the K value and calculate the accuracy**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kTop = 1\n",
    "\n",
    "Accuracy = np.sum(y_true_pred_rank <= kTop)/len(y_true_pred_rank)*100\n",
    "\n",
    "print('Accuracy:', Accuracy, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kTop = 2\n",
    "\n",
    "Accuracy = np.sum(y_true_pred_rank <= kTop)/len(y_true_pred_rank)*100\n",
    "\n",
    "print('Accuracy:', Accuracy, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kTop = 3\n",
    "\n",
    "Accuracy = np.sum(y_true_pred_rank <= kTop)/len(y_true_pred_rank)*100\n",
    "\n",
    "print('Accuracy:', Accuracy, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='Orange'>*Regression metrics - Mean Squared Error*</font>\n",
    "\n",
    "<font size=\"3\">**<span style=\"color:#4285F4\">Mean Squared Error</span> calculates the mean squared error between <span style=\"color:#4285F4\">y_true</span> and <span style=\"color:#4285F4\">y_pred</span>.**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.array([[1,   2],\n",
    "                   [1,   1]]) \n",
    "\n",
    "y_pred = np.array([[3,   2],\n",
    "                   [1,   1]]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = tf.keras.metrics.MeanSquaredError()\n",
    "metric.update_state(y_true, y_pred)\n",
    "\n",
    "print(\"Mean Squared Error:\", metric.result().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">**By calculation:**</font>\n",
    "\n",
    "><font size=\"3\">**1) Calculate squared error for each sample**</font>\n",
    "\n",
    "><font size=\"3\">**2) Calculate the mean squared error**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "squared_error = np.square((y_true-y_pred))\n",
    "\n",
    "mean_squared_error = np.mean(squared_error)\n",
    "\n",
    "print(\"Mean Squared Error:\", mean_squared_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='Orange'>*Regression metrics - Mean Absolute Error*</font>\n",
    "\n",
    "<font size=\"3\">**<span style=\"color:#4285F4\">Mean Absolute Error</span> calculates the mean absolute error between <span style=\"color:#4285F4\">y_true</span> and <span style=\"color:#4285F4\">y_pred</span>.**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.array([[1,   2],\n",
    "                   [1,   1]]) \n",
    "\n",
    "y_pred = np.array([[3,   2],\n",
    "                   [1,   1]]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = tf.keras.metrics.MeanAbsoluteError()\n",
    "metric.update_state(y_true, y_pred)\n",
    "\n",
    "print(\"Mean Absolute Error:\", metric.result().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">**By calculation:**</font>\n",
    "\n",
    "><font size=\"3\">**1) Calculate absolute error for each sample**</font>\n",
    "\n",
    "><font size=\"3\">**2) Calculate the mean absolute error**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "absolute_error = np.abs((y_true-y_pred))\n",
    "\n",
    "mean_absolute_error = np.mean(absolute_error)\n",
    "\n",
    "print(\"Mean Absolute Error:\", mean_absolute_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='Orange'>*Regression metrics - Mean Absolute Percentage Error*</font>\n",
    "\n",
    "<font size=\"3\">**<span style=\"color:#4285F4\">Mean Absolute Percentage Error</span> calculates the mean absolute percentage error between <span style=\"color:#4285F4\">y_true</span> and <span style=\"color:#4285F4\">y_pred</span>.**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.array([[1,   2],\n",
    "                   [1,   1]]) \n",
    "\n",
    "y_pred = np.array([[3,   2],\n",
    "                   [1,   1]]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = tf.keras.metrics.MeanAbsolutePercentageError()\n",
    "metric.update_state(y_true, y_pred)\n",
    "\n",
    "print(\"Mean Absolute Percentage Error:\", metric.result().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">**By calculation:**</font>\n",
    "\n",
    "><font size=\"3\">**1) Calculate absolute percentage error for each sample**</font>\n",
    "\n",
    "><font size=\"3\">**2) Calculate the mean absolute percentage error**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "absolute_error = np.abs((y_true-y_pred))\n",
    "\n",
    "absolute_percentage_error = np.divide(absolute_error, y_true)\n",
    "\n",
    "mean_absolute_percentage_error = np.mean(absolute_percentage_error)\n",
    "\n",
    "print(\"Mean Absolute Percentage Error:\", mean_absolute_percentage_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Sequential Model - Fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">**Once the model is compiled with specified <span style=\"color:#4285F4\">loss function</span>, <span style=\"color:#4285F4\">optimizer</span>, and optionally <span style=\"color:#4285F4\">some metrics</span> as well as data are ready, <span style=\"background-color: #ECECEC; color:#0047bb\">.fit()</span> method can be used to \"fit\" the model with training data to start training.**</font>\n",
    "\n",
    "<font size=\"3\">**<span style=\"background-color: #ECECEC; color:#0047bb\">.fit()</span> has two key roles:**</font>\n",
    "\n",
    "><font size=\"3\">**It will train the model by slicing the data into \"batches\" of size <span style=\"color:#4285F4\">batch_size</span>, and repeatedly iterating over the entire dataset for a given number of <span style=\"color:#4285F4\">epochs</span>.**</font>\n",
    "\n",
    "><font size=\"3\">**It will return a <span style=\"color:#4285F4\">history object</span> which holds a record of the <span style=\"color:#4285F4\">loss values</span> and <span style=\"color:#4285F4\">metric values</span> during training.**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='Orange'>Arguments</font>\n",
    "\n",
    "<font size=\"3\">**Commonly used arguments include:**</font>\n",
    "    \n",
    "><font size=\"3\">**x** - vector, matrix, or array of training data (or list if the model has multiple inputs). If all inputs in the model are named, a list mapping input names to data can also be passed.</font>\n",
    "\n",
    "><font size=\"3\">**y** - vector, matrix, or array of target (label) data (or list if the model has multiple outputs). If all outputs in the model are named, a list mapping output names to data can also be passed.</font>\n",
    "\n",
    "><font size=\"3\">**batch_size** - integer or NULL. Number of samples per gradient update. If unspecified, batch_size will default to 32.</font>\n",
    "\n",
    "><font size=\"3\">**epochs** - number of epochs to train the model. The model is trained for a number of iterations given by epochs until the epoch of index epochs is reached.</font>\n",
    "    \n",
    "><font size=\"3\">**verbose** - verbosity mode (0 = silent, 1 = progress bar, 2 = one line per epoch)</font>\n",
    "    \n",
    "><font size=\"3\">**callbacks** - list of callbacks to be called during training</font>\n",
    "    \n",
    "><font size=\"3\">**validation_split** - float between 0 and 1. Fraction of the training data to be used as validation data. The model will set apart this fraction of the training data, will not train on it, and will evaluate the loss and any model metrics on this data at the end of each epoch. The validation data is selected from the last samples in the x and y data provided, before shuffling.</font>\n",
    "\n",
    "><font size=\"3\">**validation_data**\t- data on which to evaluate the loss and any model metrics at the end of each epoch. The model will not be trained on this data. This could be a list (x_val, y_val) or a list (x_val, y_val, val_sample_weights). validation_data will override validation_split.</font>\n",
    "\n",
    "><font size=\"3\">**shuffle** - shuffle: logical (whether to shuffle the training data before each epoch) or string (for \"batch\"). \"batch\" is a special option for dealing with the limitations of HDF5 data; it shuffles in batch-sized chunks.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='Orange'>Usage of Returns</font>\n",
    "<font size=\"3\">**<span style=\"background-color: #ECECEC; color:#0047bb\">.fit()</span> returns a <span style=\"color:#4285F4\">history object</span>. Its <span style=\"background-color: #ECECEC; color:#0047bb\">History.history</span> attribute is a record of <span style=\"color:#4285F4\">training loss values</span> and <span style=\"color:#4285F4\">metrics values</span> at successive epochs, as well as validation loss values and validation metrics values (if applicable).**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='#176BEF'> Examples </font>\n",
    "<hr style=\"border:2px solid #E1F6FF\"> </hr>\n",
    "<img src=\"https://firebasestorage.googleapis.com/v0/b/deep-learning-crash-course.appspot.com/o/3NN9.png?alt=media&token=664be587-f0fe-43ec-8217-5ca7779ca0dd\" width=\"100\" align=\"right\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.random((100, 3))\n",
    "y = np.random.random((100, 1))\n",
    "\n",
    "model=Sequential()\n",
    "model.add(Dense(2, activation='relu', input_shape=(3,)))\n",
    "model.add(Dense(1, activation ='sigmoid'))\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"mse\", metrics=\"mae\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">**Store the records in <span style=\"color:#4285F4\">history object</span>**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X, y,\n",
    "                    epochs = 5,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">**Display the <span style=\"color:#4285F4\">training history</span> which is a dictionary type**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history['loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid #E1F6FF\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\"><span style=\"background-color:#EA4335; color:white\">&nbsp;!&nbsp;</span></font> <font size=\"3\">**<span style=\"color:#4285F4\">History</span> can be used to visualize the <span style=\"color:#4285F4\">error (i.e. loss)</span> on a <span style=\"color:#4285F4\">bias-variance graph</span> and allow us to render a diagnosis of the model**</font>\n",
    "\n",
    "><font size=\"3\">**<span style=\"color:#4285F4\">Bias</span> refers to the ability to capture the true patterns in the dataset.**</font>\n",
    "    \n",
    "><font size=\"3\">**<span style=\"color:#4285F4\">Variance</span> refers to the ability to capture the range of predictions for each data record.**</font>\n",
    "\n",
    "<img src=\"https://firebasestorage.googleapis.com/v0/b/deep-learning-crash-course.appspot.com/o/4NNBiasVariance1.png?alt=media&token=40cf92ff-5c74-4fe4-a8cc-68763eaef7d9\" width=\"450\" align=\"center\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">**The simplest way to understand bias-variance of a model is by looking at**</font>\n",
    "    \n",
    "><font size=\"3\">**the training set error; and**</font><br>\n",
    "><font size=\"3\">**validation/test set error.**</font>\n",
    "\n",
    "<font size=\"3\">**However, before we are able to do so, we always need a benchmark error to justify how well/bad a model perform.**</font>\n",
    "    \n",
    "<font size=\"3\">**Let's assume <span style=\"color:red\">1%</span> error can be achieved by a benchmark algorithm. If we have the following scenarios:**</font>\n",
    "\n",
    "><font size=\"3\">**1. <span style=\"color:#4285F4\"><span style=\"color:red\">1%</span> training set error, <span style=\"color:red\">1.5%</span> validataion set error</span>**</font><br>\n",
    "><font size=\"3\"></font><br>\n",
    "><font size=\"3\">**then it represents the case of <span style=\"color:green\">Low bias, Low variance</span>, which indicates that the model is perfect**</font>\n",
    "\n",
    "><font size=\"3\">**2. <span style=\"color:#4285F4\"><span style=\"color:red\">1%</span> training set error, <span style=\"color:red\">10%</span> validataion set error</span>**</font><br>\n",
    "><font size=\"3\"></font><br>\n",
    "><font size=\"3\">**then it represents the case of <span style=\"color:green\">High variance</span>, which indicates that the model does not generalize well due to <span style=\"color:#4285F4\">overfitting</span> the training**</font>\n",
    "\n",
    "><font size=\"3\">**3. <span style=\"color:#4285F4\"><span style=\"color:red\">10%</span> training set error, <span style=\"color:red\">11%</span> validataion set error</span>**</font><br>\n",
    "><font size=\"3\"></font><br>\n",
    "><font size=\"3\">**then it represents the case of <span style=\"color:green\">High bias</span>, which indicates that the model is not doing well on the training set due to <span style=\"color:#4285F4\">underfitting</span> the training**</font>\n",
    "\n",
    "><font size=\"3\">**4. <span style=\"color:#4285F4\"><span style=\"color:red\">10%</span> training set error, <span style=\"color:red\">20%</span> validataion set error</span>**</font><br>\n",
    "><font size=\"3\"></font><br>\n",
    "><font size=\"3\">**then it represents the case of <span style=\"color:green\">High bias, High variance</span>, which indicates that the model performs poorly**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='Orange'>Usage of callbacks</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">**A <span style=\"background-color: #ECECEC; color:#0047bb\">callback</span> is an object that can perform actions at various stages of training (e.g. at the start or end of an epoch, before or after a single batch, etc).**</font>\n",
    "\n",
    "<font size=\"3\">**<span style=\"background-color: #ECECEC; color:#0047bb\">Callbacks</span> can be used to:**</font>\n",
    "\n",
    "><font size=\"3\">**Write TensorBoard logs after every batch of training to monitor your metrics**</font>\n",
    "\n",
    "><font size=\"3\">**Periodically save your model to disk**</font>\n",
    "\n",
    "><font size=\"3\">**Do early stopping**</font>\n",
    "\n",
    "><font size=\"3\">**Get a view on internal states and statistics of a model during training**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">**To execute <span style=\"background-color: #ECECEC; color:#0047bb\">callbacks</span>:**</font>\n",
    "\n",
    "><font size=\"3\">**A list of callbacks (as an argument <span style=\"color:#4285F4\">callbacks</span>) can be passed to the <span style=\"background-color: #ECECEC; color:#0047bb\">.fit()</span>.**</font>\n",
    "    \n",
    "><font size=\"3\">**The relevant methods of the callbacks will then be called at each stage of the training.**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">**Commonly used functions include:**</font>\n",
    "\n",
    "><font size=\"3\">**<span style=\"color:#4285F4\">ModelCheckPoint</span>**</font>\n",
    "\n",
    "><font size=\"3\">**<span style=\"color:#4285F4\">TensorBoard</span>**</font>\n",
    "\n",
    "><font size=\"3\">**<span style=\"color:#4285F4\">EarlyStopping</span>**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='#34A853'>ModelCheckPoint</font>\n",
    "\n",
    "<font size=\"3\">**<span style=\"color:#4285F4\">ModelCheckPoint</span> callback is used in conjunction with training using <span style=\"background-color: #ECECEC; color:#0047bb\">.fit()</span> to save a model or weights (in a checkpoint file) at some interval, so the model or weights can be loaded later to continue the training from the state saved.**</font>\n",
    "\n",
    "<font size=\"3\">**A few options this callback provides include:**</font>\n",
    "\n",
    "><font size=\"3\">**Whether to only keep the model that has achieved the \"best performance\" so far, or whether to save the model at the end of every epoch regardless of performance.**</font>\n",
    "\n",
    "><font size=\"3\">**Definition of 'best'; which quantity to monitor and whether it should be maximized or minimized.**</font>\n",
    "\n",
    "><font size=\"3\">**The frequency it should save at. Currently, the callback supports saving at the end of every epoch, or after a fixed number of training batches.**</font>\n",
    "\n",
    "><font size=\"3\">**Whether only weights are saved, or the whole model is saved.**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='#176BEF'> Examples </font>\n",
    "<hr style=\"border:2px solid #E1F6FF\"> </hr>\n",
    "<img src=\"https://firebasestorage.googleapis.com/v0/b/deep-learning-crash-course.appspot.com/o/3NN9.png?alt=media&token=664be587-f0fe-43ec-8217-5ca7779ca0dd\" width=\"100\" align=\"right\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.random((100, 3))\n",
    "y = np.random.random((100, 1))\n",
    "\n",
    "model=Sequential()\n",
    "model.add(Dense(2, activation='relu', input_shape=(3,)))\n",
    "model.add(Dense(1, activation ='sigmoid'))\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"mse\", metrics=\"mae\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">**Define the callback's arguments. Commonly used arguments include:**</font>\n",
    "\n",
    "><font size=\"3\">**filepath** - it can contain named <span style=\"color:#4285F4\">formatting options</span> , which will be filled the value of <span style=\"color:#4285F4\">epoch</span> and <span style=\"color:#4285F4\">keys</span> in logs.</font><br>\n",
    "><font size=\"3\">e.g., if filepath is <span style=\"background-color: #ECECEC; color:#0047bb\">weights.{epoch:02d}-{val_loss:.2f}.hdf5</span>, then the model checkpoints will be saved with the epoch number and the validation loss in the filename.</font><br>\n",
    "><font size=\"3\">The directory of the filepath should not be reused by any other callbacks to avoid conflicts.</font>\n",
    "\n",
    "><font size=\"3\">**monitor** - it is the metric name to monitor.</font>\n",
    "\n",
    "><font size=\"3\">**save_best_only** - if <span style=\"background-color: #ECECEC; color:#0047bb\">save_best_only=True</span>, it only saves when the model is considered the <span style=\"color:#4285F4\">\"best\"</span> and the latest best model according to the quantity monitored will not be overwritten.</font><br> \n",
    "><font size=\"3\">If filepath doesn't contain <span style=\"color:#4285F4\">formatting options</span> like {epoch} then filepath will be overwritten by each new better model.</font>\n",
    "\n",
    "><font size=\"3\">**mode** - it should be one of <span style=\"color:#4285F4\">{'auto', 'min', 'max'}</span>. </font><br>\n",
    "><font size=\"3\">If <span style=\"background-color: #ECECEC; color:#0047bb\">save_best_only=True</span>, the decision to overwrite the current save file is made based on either <span style=\"color:#4285F4\">the maximization or the minimization of the monitored quantity</span>.</font><br>\n",
    "><font size=\"3\">e.g. for <span style=\"color:#4285F4\">val_acc</span>, this should be <span style=\"color:#4285F4\">max</span>, for <span style=\"color:#4285F4\">val_loss</span> this should be <span style=\"color:#4285F4\">min</span>, etc. In <span style=\"color:#4285F4\">auto</span> mode, the mode is set to <span style=\"color:#4285F4\">max</span> if the quantities monitored are <span style=\"color:#4285F4\">'acc'</span> or start with <span style=\"color:#4285F4\">'fmeasure'</span> and are set to <span style=\"color:#4285F4\">min</span> for the rest of the quantities.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "filepath = 'my_model/{epoch:02d}'\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "                            filepath,\n",
    "                            monitor='loss',\n",
    "                            mode='min',\n",
    "                            save_best_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\"><span style=\"background-color:#EA4335; color:white\">&nbsp;!&nbsp;</span></font> <font size=\"3\">**A folder (e.g. my_model folder) must be created before training.**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">**Fit the model with defined callback in a list**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X, y,\n",
    "          epochs = 5,\n",
    "          validation_split=0.2,\n",
    "          callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">**There will be five folders inside the my_model folder**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls my_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid #E1F6FF\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='#34A853'>TensorBoard</font>\n",
    "\n",
    "<font size=\"3\">**<span style=\"color:#4285F4\">TensorBoard</span> is a visualization tool provided with TensorFlow. This callback logs events for <span style=\"color:#4285F4\">TensorBoard</span>, including:**</font>\n",
    "\n",
    "><font size=\"3\">**Metrics summary plots**</font>\n",
    "\n",
    "><font size=\"3\">**Training graph visualization**</font>\n",
    "\n",
    "><font size=\"3\">**Activation histograms**</font>\n",
    "\n",
    "><font size=\"3\">**Sampled profiling**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='#176BEF'> Examples </font>\n",
    "<hr style=\"border:2px solid #E1F6FF\"> </hr>\n",
    "<img src=\"https://firebasestorage.googleapis.com/v0/b/deep-learning-crash-course.appspot.com/o/3NN9.png?alt=media&token=664be587-f0fe-43ec-8217-5ca7779ca0dd\" width=\"100\" align=\"right\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.random((100, 3))\n",
    "y = np.random.random((100, 1))\n",
    "\n",
    "model=Sequential()\n",
    "model.add(Dense(2, activation='relu', input_shape=(3,)))\n",
    "model.add(Dense(1, activation ='sigmoid'))\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"mse\", metrics=\"mae\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">**Define the callback's arguments. Commonly used arguments include:**</font>\n",
    "\n",
    "><font size=\"3\">**log_dir** - the <span style=\"color:#4285F4\">path of the directory</span> where to save the log files to be parsed by TensorBoard.</font><br>\n",
    "><font size=\"3\">The directory should not be reused by any other callbacks to avoid conflicts.</font>\n",
    "\n",
    "><font size=\"3\">**histogram_freq** - <span style=\"color:#4285F4\">frequency (in epochs)</span> at which to compute activation and weight histograms for the layers of the model.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\"><span style=\"background-color:#EA4335; color:white\">&nbsp;!&nbsp;</span></font> <font size=\"3\">**A good practice is to create folder name with current date and time.**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.0965 - mae: 0.2752WARNING:tensorflow:Callbacks method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0019s vs `on_train_batch_begin` time: 0.0120s). Check your callbacks.\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0019s vs `on_train_batch_end` time: 0.8932s). Check your callbacks.\n",
      "3/3 [==============================] - 1s 403ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 2/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 3/200\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 4/200\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 5/200\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 6/200\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 7/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 8/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 9/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 10/200\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 11/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 12/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 13/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 14/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 15/200\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 16/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 17/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 18/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 19/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 20/200\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 21/200\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 22/200\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 23/200\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 24/200\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 25/200\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 26/200\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 27/200\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 28/200\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 29/200\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 30/200\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 31/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 32/200\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 33/200\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 34/200\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 35/200\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 36/200\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 37/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 38/200\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 39/200\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 40/200\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 41/200\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 42/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 43/200\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 44/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 45/200\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 46/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 47/200\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 48/200\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 49/200\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 50/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 51/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 52/200\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 53/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 54/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 55/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 56/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 57/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 58/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 59/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 60/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 61/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 62/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 63/200\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 64/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 65/200\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 66/200\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 67/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 68/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 69/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 70/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 71/200\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 72/200\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 73/200\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 74/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 75/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 76/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 77/200\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 78/200\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 79/200\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0899 - mae: 0.2629 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 80/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.0899 - mae: 0.2629 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 81/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0899 - mae: 0.2629 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 82/200\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 83/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0899 - mae: 0.2629 - val_loss: 0.0862 - val_mae: 0.2611\n",
      "Epoch 84/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0899 - mae: 0.2629 - val_loss: 0.0862 - val_mae: 0.2611\n",
      "Epoch 85/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0899 - mae: 0.2629 - val_loss: 0.0862 - val_mae: 0.2611\n",
      "Epoch 86/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0899 - mae: 0.2629 - val_loss: 0.0862 - val_mae: 0.2611\n",
      "Epoch 87/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.0899 - mae: 0.2629 - val_loss: 0.0862 - val_mae: 0.2611\n",
      "Epoch 88/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0899 - mae: 0.2629 - val_loss: 0.0862 - val_mae: 0.2611\n",
      "Epoch 89/200\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0899 - mae: 0.2629 - val_loss: 0.0862 - val_mae: 0.2611\n",
      "Epoch 90/200\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.0899 - mae: 0.2629 - val_loss: 0.0862 - val_mae: 0.2611\n",
      "Epoch 91/200\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0899 - mae: 0.2629 - val_loss: 0.0862 - val_mae: 0.2611\n",
      "Epoch 92/200\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0899 - mae: 0.2629 - val_loss: 0.0862 - val_mae: 0.2611\n",
      "Epoch 93/200\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0899 - mae: 0.2629 - val_loss: 0.0862 - val_mae: 0.2611\n",
      "Epoch 94/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0899 - mae: 0.2629 - val_loss: 0.0862 - val_mae: 0.2611\n",
      "Epoch 95/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0862 - val_mae: 0.2611\n",
      "Epoch 96/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.0899 - mae: 0.2629 - val_loss: 0.0862 - val_mae: 0.2611\n",
      "Epoch 97/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.0899 - mae: 0.2629 - val_loss: 0.0862 - val_mae: 0.2611\n",
      "Epoch 98/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.0899 - mae: 0.2629 - val_loss: 0.0862 - val_mae: 0.2611\n",
      "Epoch 99/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0899 - mae: 0.2629 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 100/200\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0899 - mae: 0.2629 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 101/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0899 - mae: 0.2629 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 102/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 103/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 104/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 105/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.0899 - mae: 0.2629 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 106/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 107/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0899 - mae: 0.2629 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 108/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 109/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 110/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 111/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 112/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.0899 - mae: 0.2629 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 113/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 114/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 115/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.0899 - mae: 0.2629 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 116/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0899 - mae: 0.2629 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 117/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.0899 - mae: 0.2629 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 118/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0899 - mae: 0.2629 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 119/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 120/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0899 - mae: 0.2629 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 121/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.0899 - mae: 0.2629 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 122/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 123/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 124/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 125/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 126/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 127/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 128/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 129/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 130/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 131/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 132/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.0899 - mae: 0.2629 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 133/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.0899 - mae: 0.2629 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 134/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.0899 - mae: 0.2629 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 135/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0899 - mae: 0.2629 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 136/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.0899 - mae: 0.2629 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 137/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.0899 - mae: 0.2629 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 138/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 139/200\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 140/200\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 141/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 142/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 143/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 144/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 145/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 146/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 147/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 148/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 149/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 150/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 151/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 152/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 153/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 154/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 155/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 156/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 157/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 158/200\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 159/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 160/200\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 161/200\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 162/200\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 163/200\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 164/200\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 165/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 166/200\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 167/200\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 168/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 169/200\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 170/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 171/200\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 172/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 173/200\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 174/200\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 175/200\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 176/200\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 177/200\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 178/200\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 179/200\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 180/200\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 181/200\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 182/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 183/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 184/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 185/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 186/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 187/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 188/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 189/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 190/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 191/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 192/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 193/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 194/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 195/200\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0871 - mae: 0.249 - 0s 15ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 196/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 197/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 198/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 199/200\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n",
      "Epoch 200/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0899 - mae: 0.2630 - val_loss: 0.0861 - val_mae: 0.2611\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1c074dd3070>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "model.fit(X, y, \n",
    "          epochs=200, \n",
    "          validation_split=0.2,\n",
    "          callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">**Load the TensorBoard notebook extension using <span style=\"color:#4285F4\">magics</span>**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">**Start <span style=\"color:#4285F4\">TensorBoard</span> within the notebook using <span style=\"color:#4285F4\">magics</span>**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 9908), started 0:03:56 ago. (Use '!kill 9908' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-413d93a83ff9f7a\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-413d93a83ff9f7a\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">**<span style=\"color:#4285F4\">Dashboards</span> such as scalars, graphs and histograms can now be viewed.**</font>\n",
    "\n",
    "<font size=\"3\">**Alternatively, we can also start TensorBoard before training to monitor it in progress.**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs\n",
    "\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "model.fit(X, y, \n",
    "          epochs=200, \n",
    "          validation_split=0.2,\n",
    "          callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid #E1F6FF\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='#34A853'>EarlyStopping</font>\n",
    "\n",
    "<font size=\"3\">**<span style=\"color:#4285F4\">EarlyStopping</span> monitors the performance of a model for every epoch, and terminate the training when a monitored metric has stopped improving.**</font>\n",
    "\n",
    "><font size=\"3\">**Assuming the goal of a training is to <span style=\"color:#4285F4\">minimize the loss</span>. With this, the metric to be monitored would be <span style=\"color:#4285F4\">'loss'</span>, and mode would be <span style=\"color:#4285F4\">'min'</span>. A <span style=\"background-color: #ECECEC; color:#0047bb\">.fit()</span> training loop will check at end of every epoch whether the loss is no longer decreasing, considering the <span style=\"color:#4285F4\">min_delta</span> and <span style=\"color:#4285F4\">patience</span> if applicable. Once it's found no longer decreasing, the training terminates.**</font>\n",
    "\n",
    "><font size=\"3\">**The quantity to be monitored needs to be available in <span style=\"color:#4285F4\">logs dictionary</span>. To make it so, pass the loss or metrics at <span style=\"background-color: #ECECEC; color:#0047bb\">.compile()</span>.**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\"><span style=\"background-color:#EA4335; color:white\">&nbsp;!&nbsp;</span></font> <font size=\"3\">**Early stopping is a very powerful regularization technique to tackle the overfitting problem.**</font>\n",
    "    \n",
    "<font size=\"3\">**As the epochs go by, the training error and validation error naturally go down. After a while, the validation error stops decreasing and reverses. This indicates that the model has started to overfit. However, the training error continues decreasing.**</font>\n",
    "\n",
    "<font size=\"3\">**Therefore, in practice, it is more effective if early stopping is applied to <span style=\"color:#4285F4\">monitor the performance of the validation set</span> during the training.**</font>\n",
    "\n",
    "<img src=\"https://firebasestorage.googleapis.com/v0/b/deep-learning-crash-course.appspot.com/o/4NNEarlyStopping.png?alt=media&token=80522de2-05bb-470d-b434-b2dc89875763\" width=\"500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">**Commonly used arguments include:**</font>\n",
    "\n",
    "><font size=\"3\">**monitor** - Quantity to be monitored.</font><br>\n",
    "\n",
    "><font size=\"3\">**min_delta** - Minimum change in the monitored quantity to qualify as an improvement, <span style=\"color:#4285F4\">i.e. an absolute change of less than min_delta, will count as no improvement</span>.</font>\n",
    "\n",
    "><font size=\"3\">**patience** - Number of epochs with no improvement after which training will be stopped.</font><br> \n",
    "\n",
    "><font size=\"3\">**mode** - it should be one of <span style=\"color:#4285F4\">{'auto', 'min', 'max'}</span>.</font><br>\n",
    ">><font size=\"3\">In <span style=\"color:#4285F4\">min</span> mode, training will stop when the quantity monitored has stopped decreasing.</font><br>\n",
    ">><font size=\"3\">In <span style=\"color:#4285F4\">max</span> mode, training will stop when the quantity monitored has stopped increasing.</font><br>\n",
    ">><font size=\"3\">In <span style=\"color:#4285F4\">auto</span> mode, the direction is automatically inferred from the name of the monitored quantity.</font><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='#176BEF'> Examples </font>\n",
    "<hr style=\"border:2px solid #E1F6FF\"> </hr>\n",
    "<img src=\"https://firebasestorage.googleapis.com/v0/b/deep-learning-crash-course.appspot.com/o/3NN9.png?alt=media&token=664be587-f0fe-43ec-8217-5ca7779ca0dd\" width=\"100\" align=\"right\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "X = np.random.random((100, 3))\n",
    "y = np.random.random((100, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">**Define the callback's arguments - EarlyStopping on <span style=\"color:#4285F4\">Loss</span> with <span style=\"color:#4285F4\">patience</span>**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_loss=Sequential()\n",
    "model_loss.add(Dense(2, activation='relu', input_shape=(3,)))\n",
    "model_loss.add(Dense(1, activation ='sigmoid'))\n",
    "\n",
    "model_loss.compile(optimizer=\"adam\", loss=\"mse\", metrics=\"mae\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlyStopping_callback = EarlyStopping(monitor='loss', patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.0757 - mae: 0.2306 - val_loss: 0.0644 - val_mae: 0.2190\n",
      "Epoch 2/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0757 - mae: 0.2306 - val_loss: 0.0644 - val_mae: 0.2189\n",
      "Epoch 3/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0756 - mae: 0.2304 - val_loss: 0.0643 - val_mae: 0.2188\n",
      "Epoch 4/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0755 - mae: 0.2302 - val_loss: 0.0641 - val_mae: 0.2185\n",
      "Epoch 5/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0753 - mae: 0.2298 - val_loss: 0.0640 - val_mae: 0.2182\n",
      "Epoch 6/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0752 - mae: 0.2296 - val_loss: 0.0638 - val_mae: 0.2178\n",
      "Epoch 7/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0750 - mae: 0.2291 - val_loss: 0.0636 - val_mae: 0.2174\n",
      "Epoch 8/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0749 - mae: 0.2285 - val_loss: 0.0634 - val_mae: 0.2170\n",
      "Epoch 9/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0747 - mae: 0.2281 - val_loss: 0.0633 - val_mae: 0.2166\n",
      "Epoch 10/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0746 - mae: 0.2277 - val_loss: 0.0631 - val_mae: 0.2162\n",
      "Epoch 11/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0744 - mae: 0.2274 - val_loss: 0.0630 - val_mae: 0.2159\n",
      "Epoch 12/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0743 - mae: 0.2271 - val_loss: 0.0629 - val_mae: 0.2156\n",
      "Epoch 13/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.0742 - mae: 0.2268 - val_loss: 0.0629 - val_mae: 0.2154\n",
      "Epoch 14/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0742 - mae: 0.2266 - val_loss: 0.0628 - val_mae: 0.2151\n",
      "Epoch 15/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0741 - mae: 0.2263 - val_loss: 0.0627 - val_mae: 0.2149\n",
      "Epoch 16/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0740 - mae: 0.2260 - val_loss: 0.0627 - val_mae: 0.2147\n",
      "Epoch 17/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0740 - mae: 0.2259 - val_loss: 0.0626 - val_mae: 0.2145\n",
      "Epoch 18/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0739 - mae: 0.2257 - val_loss: 0.0626 - val_mae: 0.2143\n",
      "Epoch 19/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0738 - mae: 0.2256 - val_loss: 0.0625 - val_mae: 0.2141\n",
      "Epoch 20/200\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0738 - mae: 0.2254 - val_loss: 0.0625 - val_mae: 0.2139\n",
      "Epoch 21/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.0737 - mae: 0.2252 - val_loss: 0.0625 - val_mae: 0.2137\n",
      "Epoch 22/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.0737 - mae: 0.2251 - val_loss: 0.0624 - val_mae: 0.2135\n",
      "Epoch 23/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0737 - mae: 0.2250 - val_loss: 0.0624 - val_mae: 0.2134\n",
      "Epoch 24/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0737 - mae: 0.2248 - val_loss: 0.0624 - val_mae: 0.2132\n",
      "Epoch 25/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0736 - mae: 0.2247 - val_loss: 0.0624 - val_mae: 0.2131\n",
      "Epoch 26/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.0736 - mae: 0.2246 - val_loss: 0.0623 - val_mae: 0.2131\n",
      "Epoch 27/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.0736 - mae: 0.2245 - val_loss: 0.0623 - val_mae: 0.2130\n",
      "Epoch 28/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0735 - mae: 0.2243 - val_loss: 0.0623 - val_mae: 0.2130\n",
      "Epoch 29/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.0735 - mae: 0.2242 - val_loss: 0.0623 - val_mae: 0.2130\n",
      "Epoch 30/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0735 - mae: 0.2241 - val_loss: 0.0623 - val_mae: 0.2130\n",
      "Epoch 31/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0735 - mae: 0.2240 - val_loss: 0.0623 - val_mae: 0.2130\n",
      "Epoch 32/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.0735 - mae: 0.2239 - val_loss: 0.0623 - val_mae: 0.2129\n",
      "Epoch 33/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.0734 - mae: 0.2238 - val_loss: 0.0623 - val_mae: 0.2129\n",
      "Epoch 34/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.0734 - mae: 0.2238 - val_loss: 0.0623 - val_mae: 0.2129\n",
      "Epoch 35/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0734 - mae: 0.2238 - val_loss: 0.0623 - val_mae: 0.2129\n",
      "Epoch 36/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.0734 - mae: 0.2238 - val_loss: 0.0623 - val_mae: 0.2129\n",
      "Epoch 37/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.0734 - mae: 0.2237 - val_loss: 0.0623 - val_mae: 0.2129\n",
      "Epoch 38/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.0734 - mae: 0.2237 - val_loss: 0.0623 - val_mae: 0.2129\n",
      "Epoch 39/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.0734 - mae: 0.2238 - val_loss: 0.0623 - val_mae: 0.2129\n",
      "Epoch 40/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0734 - mae: 0.2238 - val_loss: 0.0623 - val_mae: 0.2129\n",
      "Epoch 41/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0734 - mae: 0.2238 - val_loss: 0.0623 - val_mae: 0.2129\n",
      "Epoch 42/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0733 - mae: 0.2237 - val_loss: 0.0623 - val_mae: 0.2129\n",
      "Epoch 43/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0733 - mae: 0.2238 - val_loss: 0.0623 - val_mae: 0.2129\n",
      "Epoch 44/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.0733 - mae: 0.2237 - val_loss: 0.0623 - val_mae: 0.2129\n",
      "Epoch 45/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.0733 - mae: 0.2237 - val_loss: 0.0623 - val_mae: 0.2129\n",
      "Epoch 46/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.0733 - mae: 0.2236 - val_loss: 0.0623 - val_mae: 0.2128\n",
      "Epoch 47/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.0733 - mae: 0.2235 - val_loss: 0.0623 - val_mae: 0.2128\n",
      "Epoch 48/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.0733 - mae: 0.2235 - val_loss: 0.0623 - val_mae: 0.2128\n",
      "Epoch 49/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.0733 - mae: 0.2234 - val_loss: 0.0623 - val_mae: 0.2128\n",
      "Epoch 50/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.0732 - mae: 0.2234 - val_loss: 0.0623 - val_mae: 0.2128\n",
      "Epoch 51/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.0732 - mae: 0.2234 - val_loss: 0.0623 - val_mae: 0.2128\n",
      "Epoch 52/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0732 - mae: 0.2234 - val_loss: 0.0623 - val_mae: 0.2128\n",
      "Epoch 53/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.0732 - mae: 0.2234 - val_loss: 0.0623 - val_mae: 0.2128\n",
      "Epoch 54/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.0732 - mae: 0.2234 - val_loss: 0.0623 - val_mae: 0.2128\n",
      "Epoch 55/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.0732 - mae: 0.2234 - val_loss: 0.0623 - val_mae: 0.2128\n",
      "Epoch 56/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.0732 - mae: 0.2234 - val_loss: 0.0623 - val_mae: 0.2128\n",
      "Epoch 57/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.0732 - mae: 0.2234 - val_loss: 0.0623 - val_mae: 0.2128\n",
      "Epoch 58/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0732 - mae: 0.2234 - val_loss: 0.0623 - val_mae: 0.2128\n",
      "Epoch 59/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0732 - mae: 0.2234 - val_loss: 0.0623 - val_mae: 0.2127\n",
      "Epoch 60/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0731 - mae: 0.2233 - val_loss: 0.0623 - val_mae: 0.2127\n",
      "Epoch 61/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0731 - mae: 0.2233 - val_loss: 0.0623 - val_mae: 0.2127\n",
      "Epoch 62/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.0731 - mae: 0.2232 - val_loss: 0.0623 - val_mae: 0.2127\n",
      "Epoch 63/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0731 - mae: 0.2231 - val_loss: 0.0623 - val_mae: 0.2127\n",
      "Epoch 64/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.0731 - mae: 0.2231 - val_loss: 0.0623 - val_mae: 0.2127\n",
      "Epoch 65/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0731 - mae: 0.2231 - val_loss: 0.0623 - val_mae: 0.2127\n",
      "Epoch 66/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.0731 - mae: 0.2231 - val_loss: 0.0623 - val_mae: 0.2127\n",
      "Epoch 67/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.0731 - mae: 0.2231 - val_loss: 0.0623 - val_mae: 0.2127\n",
      "Epoch 68/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0730 - mae: 0.2231 - val_loss: 0.0623 - val_mae: 0.2127\n",
      "Epoch 69/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0730 - mae: 0.2231 - val_loss: 0.0623 - val_mae: 0.2127\n",
      "Epoch 70/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0730 - mae: 0.2231 - val_loss: 0.0623 - val_mae: 0.2127\n",
      "Epoch 71/200\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0730 - mae: 0.2231 - val_loss: 0.0623 - val_mae: 0.2127\n",
      "Epoch 72/200\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0730 - mae: 0.2230 - val_loss: 0.0623 - val_mae: 0.2126\n",
      "Epoch 73/200\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0730 - mae: 0.2230 - val_loss: 0.0623 - val_mae: 0.2126\n",
      "Epoch 74/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0730 - mae: 0.2230 - val_loss: 0.0623 - val_mae: 0.2126\n",
      "Epoch 75/200\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0730 - mae: 0.2230 - val_loss: 0.0623 - val_mae: 0.2126\n",
      "Epoch 76/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0729 - mae: 0.2229 - val_loss: 0.0623 - val_mae: 0.2126\n",
      "Epoch 77/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0729 - mae: 0.2229 - val_loss: 0.0623 - val_mae: 0.2126\n",
      "Epoch 78/200\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0729 - mae: 0.2229 - val_loss: 0.0623 - val_mae: 0.2126\n",
      "Epoch 79/200\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0729 - mae: 0.2229 - val_loss: 0.0623 - val_mae: 0.2126\n",
      "Epoch 80/200\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0729 - mae: 0.2229 - val_loss: 0.0623 - val_mae: 0.2126\n",
      "Epoch 81/200\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0729 - mae: 0.2229 - val_loss: 0.0623 - val_mae: 0.2126\n",
      "Epoch 82/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0729 - mae: 0.2229 - val_loss: 0.0623 - val_mae: 0.2126\n",
      "Epoch 83/200\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0729 - mae: 0.2228 - val_loss: 0.0623 - val_mae: 0.2126\n",
      "Epoch 84/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0728 - mae: 0.2228 - val_loss: 0.0623 - val_mae: 0.2126\n",
      "Epoch 85/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0728 - mae: 0.2228 - val_loss: 0.0623 - val_mae: 0.2126\n",
      "Epoch 86/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0728 - mae: 0.2228 - val_loss: 0.0623 - val_mae: 0.2126\n",
      "Epoch 87/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0728 - mae: 0.2228 - val_loss: 0.0623 - val_mae: 0.2126\n",
      "Epoch 88/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0728 - mae: 0.2227 - val_loss: 0.0623 - val_mae: 0.2126\n",
      "Epoch 89/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0728 - mae: 0.2227 - val_loss: 0.0623 - val_mae: 0.2126\n",
      "Epoch 90/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0728 - mae: 0.2227 - val_loss: 0.0624 - val_mae: 0.2126\n",
      "Epoch 91/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0728 - mae: 0.2227 - val_loss: 0.0624 - val_mae: 0.2126\n",
      "Epoch 92/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0728 - mae: 0.2227 - val_loss: 0.0624 - val_mae: 0.2126\n",
      "Epoch 93/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0727 - mae: 0.2227 - val_loss: 0.0624 - val_mae: 0.2126\n",
      "Epoch 94/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0727 - mae: 0.2226 - val_loss: 0.0624 - val_mae: 0.2126\n",
      "Epoch 95/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0727 - mae: 0.2226 - val_loss: 0.0624 - val_mae: 0.2126\n",
      "Epoch 96/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.0727 - mae: 0.2227 - val_loss: 0.0624 - val_mae: 0.2126\n",
      "Epoch 97/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0727 - mae: 0.2227 - val_loss: 0.0624 - val_mae: 0.2126\n",
      "Epoch 98/200\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0727 - mae: 0.2227 - val_loss: 0.0624 - val_mae: 0.2126\n",
      "Epoch 99/200\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0727 - mae: 0.2227 - val_loss: 0.0624 - val_mae: 0.2126\n",
      "Epoch 100/200\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0727 - mae: 0.2227 - val_loss: 0.0624 - val_mae: 0.2126\n",
      "Epoch 101/200\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.0727 - mae: 0.2227 - val_loss: 0.0624 - val_mae: 0.2125\n",
      "Epoch 102/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0727 - mae: 0.2226 - val_loss: 0.0624 - val_mae: 0.2125\n",
      "Epoch 103/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.0726 - mae: 0.2226 - val_loss: 0.0624 - val_mae: 0.2125\n",
      "Epoch 104/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0726 - mae: 0.2226 - val_loss: 0.0624 - val_mae: 0.2125\n",
      "Epoch 105/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.0726 - mae: 0.2226 - val_loss: 0.0624 - val_mae: 0.2125\n",
      "Epoch 106/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.0726 - mae: 0.2226 - val_loss: 0.0624 - val_mae: 0.2125\n",
      "Epoch 107/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.0726 - mae: 0.2225 - val_loss: 0.0624 - val_mae: 0.2125\n",
      "Epoch 108/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0726 - mae: 0.2225 - val_loss: 0.0624 - val_mae: 0.2124\n",
      "Epoch 109/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0726 - mae: 0.2226 - val_loss: 0.0624 - val_mae: 0.2124\n",
      "Epoch 110/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0726 - mae: 0.2225 - val_loss: 0.0624 - val_mae: 0.2124\n",
      "Epoch 111/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0726 - mae: 0.2225 - val_loss: 0.0624 - val_mae: 0.2124\n",
      "Epoch 112/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0726 - mae: 0.2225 - val_loss: 0.0624 - val_mae: 0.2124\n",
      "Epoch 113/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0725 - mae: 0.2224 - val_loss: 0.0624 - val_mae: 0.2124\n",
      "Epoch 114/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0725 - mae: 0.2224 - val_loss: 0.0624 - val_mae: 0.2124\n",
      "Epoch 115/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.0725 - mae: 0.2225 - val_loss: 0.0624 - val_mae: 0.2124\n",
      "Epoch 116/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0725 - mae: 0.2225 - val_loss: 0.0624 - val_mae: 0.2124\n",
      "Epoch 117/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0725 - mae: 0.2226 - val_loss: 0.0624 - val_mae: 0.2124\n",
      "Epoch 118/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0725 - mae: 0.2226 - val_loss: 0.0624 - val_mae: 0.2123\n",
      "Epoch 119/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0725 - mae: 0.2226 - val_loss: 0.0624 - val_mae: 0.2123\n",
      "Epoch 120/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0725 - mae: 0.2226 - val_loss: 0.0624 - val_mae: 0.2123\n",
      "Epoch 121/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.0725 - mae: 0.2226 - val_loss: 0.0624 - val_mae: 0.2123\n",
      "Epoch 122/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.0724 - mae: 0.2226 - val_loss: 0.0624 - val_mae: 0.2123\n",
      "Epoch 123/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0724 - mae: 0.2226 - val_loss: 0.0624 - val_mae: 0.2123\n",
      "Epoch 124/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0724 - mae: 0.2226 - val_loss: 0.0624 - val_mae: 0.2123\n",
      "Epoch 125/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0724 - mae: 0.2226 - val_loss: 0.0624 - val_mae: 0.2123\n",
      "Epoch 126/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0724 - mae: 0.2226 - val_loss: 0.0624 - val_mae: 0.2123\n",
      "Epoch 127/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.0724 - mae: 0.2226 - val_loss: 0.0624 - val_mae: 0.2123\n",
      "Epoch 128/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.0724 - mae: 0.2227 - val_loss: 0.0624 - val_mae: 0.2123\n",
      "Epoch 129/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.0724 - mae: 0.2227 - val_loss: 0.0624 - val_mae: 0.2123\n",
      "Epoch 130/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.0724 - mae: 0.2227 - val_loss: 0.0625 - val_mae: 0.2123\n",
      "Epoch 131/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0724 - mae: 0.2227 - val_loss: 0.0624 - val_mae: 0.2123\n",
      "Epoch 132/200\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.0724 - mae: 0.2226 - val_loss: 0.0625 - val_mae: 0.2123\n",
      "Epoch 133/200\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0724 - mae: 0.2226 - val_loss: 0.0625 - val_mae: 0.2123\n",
      "Epoch 134/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.0723 - mae: 0.2226 - val_loss: 0.0625 - val_mae: 0.2123\n",
      "Epoch 135/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0723 - mae: 0.2226 - val_loss: 0.0625 - val_mae: 0.2123\n",
      "Epoch 136/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0723 - mae: 0.2227 - val_loss: 0.0625 - val_mae: 0.2123\n",
      "Epoch 137/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0723 - mae: 0.2227 - val_loss: 0.0625 - val_mae: 0.2123\n",
      "Epoch 138/200\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0723 - mae: 0.2226 - val_loss: 0.0625 - val_mae: 0.2123\n",
      "Epoch 139/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0723 - mae: 0.2226 - val_loss: 0.0625 - val_mae: 0.2123\n",
      "Epoch 140/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.0723 - mae: 0.2226 - val_loss: 0.0625 - val_mae: 0.2122\n",
      "Epoch 141/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0723 - mae: 0.2225 - val_loss: 0.0625 - val_mae: 0.2122\n",
      "Epoch 142/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0723 - mae: 0.2225 - val_loss: 0.0625 - val_mae: 0.2122\n",
      "Epoch 143/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.0723 - mae: 0.2226 - val_loss: 0.0625 - val_mae: 0.2122\n",
      "Epoch 144/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0723 - mae: 0.2225 - val_loss: 0.0625 - val_mae: 0.2122\n",
      "Epoch 145/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0723 - mae: 0.2225 - val_loss: 0.0625 - val_mae: 0.2122\n",
      "Epoch 146/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0723 - mae: 0.2225 - val_loss: 0.0625 - val_mae: 0.2122\n",
      "Epoch 147/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0723 - mae: 0.2225 - val_loss: 0.0624 - val_mae: 0.2122\n",
      "Epoch 148/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.0722 - mae: 0.2225 - val_loss: 0.0624 - val_mae: 0.2121\n",
      "Epoch 149/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0722 - mae: 0.2224 - val_loss: 0.0624 - val_mae: 0.2121\n",
      "Epoch 150/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0722 - mae: 0.2224 - val_loss: 0.0624 - val_mae: 0.2121\n",
      "Epoch 151/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0722 - mae: 0.2223 - val_loss: 0.0624 - val_mae: 0.2121\n",
      "Epoch 152/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0722 - mae: 0.2222 - val_loss: 0.0624 - val_mae: 0.2121\n",
      "Epoch 153/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0722 - mae: 0.2222 - val_loss: 0.0624 - val_mae: 0.2121\n",
      "Epoch 154/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0722 - mae: 0.2221 - val_loss: 0.0624 - val_mae: 0.2121\n",
      "Epoch 155/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0722 - mae: 0.2221 - val_loss: 0.0624 - val_mae: 0.2121\n",
      "Epoch 156/200\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0722 - mae: 0.2220 - val_loss: 0.0624 - val_mae: 0.2120\n",
      "Epoch 157/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.0722 - mae: 0.2220 - val_loss: 0.0624 - val_mae: 0.2120\n",
      "Epoch 158/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0722 - mae: 0.2220 - val_loss: 0.0624 - val_mae: 0.2120\n",
      "Epoch 159/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0722 - mae: 0.2220 - val_loss: 0.0624 - val_mae: 0.2120\n",
      "Epoch 160/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.0722 - mae: 0.2220 - val_loss: 0.0624 - val_mae: 0.2120\n",
      "Epoch 161/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0722 - mae: 0.2220 - val_loss: 0.0624 - val_mae: 0.2120\n",
      "Epoch 162/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0722 - mae: 0.2220 - val_loss: 0.0624 - val_mae: 0.2120\n",
      "Epoch 163/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0721 - mae: 0.2220 - val_loss: 0.0624 - val_mae: 0.2120\n",
      "Epoch 164/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.0721 - mae: 0.2220 - val_loss: 0.0624 - val_mae: 0.2120\n",
      "Epoch 165/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0721 - mae: 0.2219 - val_loss: 0.0624 - val_mae: 0.2120\n",
      "Epoch 166/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.0721 - mae: 0.2219 - val_loss: 0.0624 - val_mae: 0.2119\n",
      "Epoch 167/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.0721 - mae: 0.2218 - val_loss: 0.0624 - val_mae: 0.2119\n",
      "Epoch 168/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.0721 - mae: 0.2218 - val_loss: 0.0624 - val_mae: 0.2119\n",
      "Epoch 169/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0721 - mae: 0.2217 - val_loss: 0.0624 - val_mae: 0.2119\n",
      "Epoch 170/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.0721 - mae: 0.2216 - val_loss: 0.0624 - val_mae: 0.2119\n",
      "Epoch 171/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.0721 - mae: 0.2216 - val_loss: 0.0624 - val_mae: 0.2118\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x24e9aff6cd0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_loss.fit(X, y,\n",
    "          epochs = 200,\n",
    "          validation_split=0.2,\n",
    "          callbacks=[earlyStopping_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">**Define the callback's arguments - EarlyStopping on <span style=\"color:#4285F4\">Validation Loss</span> with <span style=\"color:#4285F4\">patience</span>**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_val_loss=Sequential()\n",
    "model_val_loss.add(Dense(2, activation='relu', input_shape=(3,)))\n",
    "model_val_loss.add(Dense(1, activation ='sigmoid'))\n",
    "\n",
    "model_val_loss.compile(optimizer=\"adam\", loss=\"mse\", metrics=\"mae\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlyStopping_callback = EarlyStopping(monitor='val_loss', patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0810 - mae: 0.2407 - val_loss: 0.0702 - val_mae: 0.2243\n",
      "Epoch 2/500\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0808 - mae: 0.2404 - val_loss: 0.0700 - val_mae: 0.2241\n",
      "Epoch 3/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0805 - mae: 0.2400 - val_loss: 0.0699 - val_mae: 0.2239\n",
      "Epoch 4/500\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.0804 - mae: 0.2397 - val_loss: 0.0697 - val_mae: 0.2236\n",
      "Epoch 5/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0801 - mae: 0.2393 - val_loss: 0.0695 - val_mae: 0.2234\n",
      "Epoch 6/500\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0799 - mae: 0.2390 - val_loss: 0.0693 - val_mae: 0.2231\n",
      "Epoch 7/500\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0797 - mae: 0.2387 - val_loss: 0.0692 - val_mae: 0.2230\n",
      "Epoch 8/500\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0795 - mae: 0.2383 - val_loss: 0.0690 - val_mae: 0.2229\n",
      "Epoch 9/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0793 - mae: 0.2381 - val_loss: 0.0689 - val_mae: 0.2229\n",
      "Epoch 10/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0792 - mae: 0.2378 - val_loss: 0.0687 - val_mae: 0.2228\n",
      "Epoch 11/500\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0790 - mae: 0.2374 - val_loss: 0.0686 - val_mae: 0.2227\n",
      "Epoch 12/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0788 - mae: 0.2372 - val_loss: 0.0684 - val_mae: 0.2226\n",
      "Epoch 13/500\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0786 - mae: 0.2368 - val_loss: 0.0683 - val_mae: 0.2226\n",
      "Epoch 14/500\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.0785 - mae: 0.2366 - val_loss: 0.0682 - val_mae: 0.2225\n",
      "Epoch 15/500\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0783 - mae: 0.2363 - val_loss: 0.0681 - val_mae: 0.2225\n",
      "Epoch 16/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0781 - mae: 0.2360 - val_loss: 0.0680 - val_mae: 0.2225\n",
      "Epoch 17/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0780 - mae: 0.2357 - val_loss: 0.0679 - val_mae: 0.2224\n",
      "Epoch 18/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0778 - mae: 0.2355 - val_loss: 0.0678 - val_mae: 0.2224\n",
      "Epoch 19/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0777 - mae: 0.2351 - val_loss: 0.0677 - val_mae: 0.2223\n",
      "Epoch 20/500\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0775 - mae: 0.2348 - val_loss: 0.0676 - val_mae: 0.2223\n",
      "Epoch 21/500\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0774 - mae: 0.2346 - val_loss: 0.0675 - val_mae: 0.2222\n",
      "Epoch 22/500\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.0772 - mae: 0.2343 - val_loss: 0.0675 - val_mae: 0.2222\n",
      "Epoch 23/500\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0770 - mae: 0.2340 - val_loss: 0.0674 - val_mae: 0.2221\n",
      "Epoch 24/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0769 - mae: 0.2337 - val_loss: 0.0673 - val_mae: 0.2221\n",
      "Epoch 25/500\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0768 - mae: 0.2334 - val_loss: 0.0672 - val_mae: 0.2220\n",
      "Epoch 26/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0766 - mae: 0.2331 - val_loss: 0.0671 - val_mae: 0.2220\n",
      "Epoch 27/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0765 - mae: 0.2328 - val_loss: 0.0671 - val_mae: 0.2220\n",
      "Epoch 28/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0764 - mae: 0.2326 - val_loss: 0.0670 - val_mae: 0.2220\n",
      "Epoch 29/500\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0763 - mae: 0.2324 - val_loss: 0.0670 - val_mae: 0.2219\n",
      "Epoch 30/500\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0761 - mae: 0.2321 - val_loss: 0.0669 - val_mae: 0.2219\n",
      "Epoch 31/500\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0760 - mae: 0.2319 - val_loss: 0.0669 - val_mae: 0.2219\n",
      "Epoch 32/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0759 - mae: 0.2316 - val_loss: 0.0669 - val_mae: 0.2219\n",
      "Epoch 33/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0758 - mae: 0.2315 - val_loss: 0.0668 - val_mae: 0.2219\n",
      "Epoch 34/500\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0757 - mae: 0.2313 - val_loss: 0.0668 - val_mae: 0.2219\n",
      "Epoch 35/500\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0756 - mae: 0.2311 - val_loss: 0.0668 - val_mae: 0.2219\n",
      "Epoch 36/500\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0755 - mae: 0.2309 - val_loss: 0.0667 - val_mae: 0.2218\n",
      "Epoch 37/500\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0754 - mae: 0.2307 - val_loss: 0.0667 - val_mae: 0.2218\n",
      "Epoch 38/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0753 - mae: 0.2304 - val_loss: 0.0666 - val_mae: 0.2218\n",
      "Epoch 39/500\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0752 - mae: 0.2302 - val_loss: 0.0666 - val_mae: 0.2217\n",
      "Epoch 40/500\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0751 - mae: 0.2300 - val_loss: 0.0666 - val_mae: 0.2217\n",
      "Epoch 41/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0750 - mae: 0.2298 - val_loss: 0.0665 - val_mae: 0.2217\n",
      "Epoch 42/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0749 - mae: 0.2296 - val_loss: 0.0665 - val_mae: 0.2217\n",
      "Epoch 43/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0748 - mae: 0.2295 - val_loss: 0.0665 - val_mae: 0.2216\n",
      "Epoch 44/500\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0747 - mae: 0.2293 - val_loss: 0.0664 - val_mae: 0.2216\n",
      "Epoch 45/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0746 - mae: 0.2292 - val_loss: 0.0664 - val_mae: 0.2216\n",
      "Epoch 46/500\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0746 - mae: 0.2290 - val_loss: 0.0664 - val_mae: 0.2216\n",
      "Epoch 47/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0745 - mae: 0.2289 - val_loss: 0.0664 - val_mae: 0.2216\n",
      "Epoch 48/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0744 - mae: 0.2288 - val_loss: 0.0664 - val_mae: 0.2215\n",
      "Epoch 49/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0744 - mae: 0.2287 - val_loss: 0.0664 - val_mae: 0.2215\n",
      "Epoch 50/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0743 - mae: 0.2285 - val_loss: 0.0663 - val_mae: 0.2215\n",
      "Epoch 51/500\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0742 - mae: 0.2284 - val_loss: 0.0663 - val_mae: 0.2215\n",
      "Epoch 52/500\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0742 - mae: 0.2284 - val_loss: 0.0663 - val_mae: 0.2215\n",
      "Epoch 53/500\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0741 - mae: 0.2282 - val_loss: 0.0663 - val_mae: 0.2215\n",
      "Epoch 54/500\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0741 - mae: 0.2281 - val_loss: 0.0663 - val_mae: 0.2214\n",
      "Epoch 55/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0740 - mae: 0.2280 - val_loss: 0.0663 - val_mae: 0.2214\n",
      "Epoch 56/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0740 - mae: 0.2280 - val_loss: 0.0663 - val_mae: 0.2214\n",
      "Epoch 57/500\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0739 - mae: 0.2279 - val_loss: 0.0663 - val_mae: 0.2214\n",
      "Epoch 58/500\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0739 - mae: 0.2278 - val_loss: 0.0663 - val_mae: 0.2213\n",
      "Epoch 59/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0738 - mae: 0.2277 - val_loss: 0.0663 - val_mae: 0.2213\n",
      "Epoch 60/500\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0738 - mae: 0.2277 - val_loss: 0.0662 - val_mae: 0.2213\n",
      "Epoch 61/500\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0737 - mae: 0.2276 - val_loss: 0.0662 - val_mae: 0.2213\n",
      "Epoch 62/500\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.0737 - mae: 0.2275 - val_loss: 0.0662 - val_mae: 0.2213\n",
      "Epoch 63/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0737 - mae: 0.2274 - val_loss: 0.0662 - val_mae: 0.2212\n",
      "Epoch 64/500\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0737 - mae: 0.2274 - val_loss: 0.0662 - val_mae: 0.2212\n",
      "Epoch 65/500\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0736 - mae: 0.2273 - val_loss: 0.0662 - val_mae: 0.2212\n",
      "Epoch 66/500\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.0736 - mae: 0.2272 - val_loss: 0.0662 - val_mae: 0.2212\n",
      "Epoch 67/500\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0735 - mae: 0.2271 - val_loss: 0.0662 - val_mae: 0.2211\n",
      "Epoch 68/500\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.0735 - mae: 0.2271 - val_loss: 0.0662 - val_mae: 0.2211\n",
      "Epoch 69/500\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0735 - mae: 0.2270 - val_loss: 0.0662 - val_mae: 0.2211\n",
      "Epoch 70/500\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.0734 - mae: 0.2269 - val_loss: 0.0662 - val_mae: 0.2211\n",
      "Epoch 71/500\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.0734 - mae: 0.2269 - val_loss: 0.0662 - val_mae: 0.2210\n",
      "Epoch 72/500\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0734 - mae: 0.2267 - val_loss: 0.0662 - val_mae: 0.2210\n",
      "Epoch 73/500\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.0733 - mae: 0.2267 - val_loss: 0.0662 - val_mae: 0.2210\n",
      "Epoch 74/500\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.0733 - mae: 0.2266 - val_loss: 0.0662 - val_mae: 0.2210\n",
      "Epoch 75/500\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0733 - mae: 0.2266 - val_loss: 0.0662 - val_mae: 0.2209\n",
      "Epoch 76/500\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.0733 - mae: 0.2265 - val_loss: 0.0662 - val_mae: 0.2209\n",
      "Epoch 77/500\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0732 - mae: 0.2264 - val_loss: 0.0662 - val_mae: 0.2209\n",
      "Epoch 78/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0732 - mae: 0.2264 - val_loss: 0.0662 - val_mae: 0.2209\n",
      "Epoch 79/500\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.0732 - mae: 0.2263 - val_loss: 0.0662 - val_mae: 0.2209\n",
      "Epoch 80/500\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.0732 - mae: 0.2263 - val_loss: 0.0662 - val_mae: 0.2208\n",
      "Epoch 81/500\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.0731 - mae: 0.2262 - val_loss: 0.0662 - val_mae: 0.2208\n",
      "Epoch 82/500\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0731 - mae: 0.2262 - val_loss: 0.0662 - val_mae: 0.2208\n",
      "Epoch 83/500\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.0731 - mae: 0.2261 - val_loss: 0.0662 - val_mae: 0.2208\n",
      "Epoch 84/500\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.0731 - mae: 0.2260 - val_loss: 0.0662 - val_mae: 0.2207\n",
      "Epoch 85/500\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.0731 - mae: 0.2260 - val_loss: 0.0662 - val_mae: 0.2207\n",
      "Epoch 86/500\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.0730 - mae: 0.2259 - val_loss: 0.0662 - val_mae: 0.2207\n",
      "Epoch 87/500\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.0730 - mae: 0.2259 - val_loss: 0.0662 - val_mae: 0.2207\n",
      "Epoch 88/500\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.0730 - mae: 0.2258 - val_loss: 0.0662 - val_mae: 0.2206\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x24e9b0de160>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_val_loss.fit(X, y,\n",
    "          epochs = 500,\n",
    "          validation_split=0.2,\n",
    "          callbacks=[earlyStopping_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">**Define the callback's arguments - EarlyStopping on <span style=\"color:#4285F4\">Validation Loss</span> with <span style=\"color:#4285F4\">min_delta</span>**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_min_delta=Sequential()\n",
    "model_min_delta.add(Dense(2, activation='relu', input_shape=(3,)))\n",
    "model_min_delta.add(Dense(1, activation ='sigmoid'))\n",
    "\n",
    "model_min_delta.compile(optimizer=\"adam\", loss=\"mse\", metrics=\"mae\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlyStopping_callback = EarlyStopping(monitor='val_loss', min_delta=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0828 - mae: 0.2437 - val_loss: 0.0727 - val_mae: 0.2292\n",
      "Epoch 2/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0825 - mae: 0.2432 - val_loss: 0.0724 - val_mae: 0.2286\n",
      "Epoch 3/500\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.0822 - mae: 0.2427 - val_loss: 0.0721 - val_mae: 0.2282\n",
      "Epoch 4/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0819 - mae: 0.2421 - val_loss: 0.0719 - val_mae: 0.2278\n",
      "Epoch 5/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0816 - mae: 0.2416 - val_loss: 0.0716 - val_mae: 0.2275\n",
      "Epoch 6/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0813 - mae: 0.2412 - val_loss: 0.0714 - val_mae: 0.2271\n",
      "Epoch 7/500\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0811 - mae: 0.2408 - val_loss: 0.0711 - val_mae: 0.2267\n",
      "Epoch 8/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0808 - mae: 0.2403 - val_loss: 0.0709 - val_mae: 0.2264\n",
      "Epoch 9/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0806 - mae: 0.2398 - val_loss: 0.0707 - val_mae: 0.2261\n",
      "Epoch 10/500\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0804 - mae: 0.2395 - val_loss: 0.0704 - val_mae: 0.2259\n",
      "Epoch 11/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0801 - mae: 0.2390 - val_loss: 0.0702 - val_mae: 0.2257\n",
      "Epoch 12/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0799 - mae: 0.2386 - val_loss: 0.0700 - val_mae: 0.2255\n",
      "Epoch 13/500\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0797 - mae: 0.2382 - val_loss: 0.0698 - val_mae: 0.2253\n",
      "Epoch 14/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0794 - mae: 0.2378 - val_loss: 0.0696 - val_mae: 0.2251\n",
      "Epoch 15/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0792 - mae: 0.2375 - val_loss: 0.0695 - val_mae: 0.2249\n",
      "Epoch 16/500\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0790 - mae: 0.2371 - val_loss: 0.0693 - val_mae: 0.2247\n",
      "Epoch 17/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0789 - mae: 0.2368 - val_loss: 0.0691 - val_mae: 0.2246\n",
      "Epoch 18/500\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0787 - mae: 0.2365 - val_loss: 0.0690 - val_mae: 0.2244\n",
      "Epoch 19/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0785 - mae: 0.2362 - val_loss: 0.0689 - val_mae: 0.2242\n",
      "Epoch 20/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0783 - mae: 0.2359 - val_loss: 0.0687 - val_mae: 0.2241\n",
      "Epoch 21/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0782 - mae: 0.2356 - val_loss: 0.0686 - val_mae: 0.2239\n",
      "Epoch 22/500\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0780 - mae: 0.2354 - val_loss: 0.0685 - val_mae: 0.2237\n",
      "Epoch 23/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0779 - mae: 0.2350 - val_loss: 0.0683 - val_mae: 0.2236\n",
      "Epoch 24/500\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0777 - mae: 0.2348 - val_loss: 0.0682 - val_mae: 0.2234\n",
      "Epoch 25/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0776 - mae: 0.2345 - val_loss: 0.0681 - val_mae: 0.2233\n",
      "Epoch 26/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0774 - mae: 0.2343 - val_loss: 0.0680 - val_mae: 0.2231\n",
      "Epoch 27/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0773 - mae: 0.2340 - val_loss: 0.0679 - val_mae: 0.2230\n",
      "Epoch 28/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0772 - mae: 0.2338 - val_loss: 0.0678 - val_mae: 0.2229\n",
      "Epoch 29/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0771 - mae: 0.2336 - val_loss: 0.0677 - val_mae: 0.2227\n",
      "Epoch 30/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0769 - mae: 0.2333 - val_loss: 0.0676 - val_mae: 0.2226\n",
      "Epoch 31/500\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.0768 - mae: 0.2331 - val_loss: 0.0675 - val_mae: 0.2225\n",
      "Epoch 32/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0767 - mae: 0.2328 - val_loss: 0.0674 - val_mae: 0.2223\n",
      "Epoch 33/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0766 - mae: 0.2326 - val_loss: 0.0673 - val_mae: 0.2222\n",
      "Epoch 34/500\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0765 - mae: 0.2324 - val_loss: 0.0672 - val_mae: 0.2221\n",
      "Epoch 35/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0764 - mae: 0.2322 - val_loss: 0.0671 - val_mae: 0.2220\n",
      "Epoch 36/500\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0763 - mae: 0.2320 - val_loss: 0.0670 - val_mae: 0.2218\n",
      "Epoch 37/500\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.0762 - mae: 0.2318 - val_loss: 0.0669 - val_mae: 0.2217\n",
      "Epoch 38/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0761 - mae: 0.2316 - val_loss: 0.0669 - val_mae: 0.2216\n",
      "Epoch 39/500\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0760 - mae: 0.2314 - val_loss: 0.0668 - val_mae: 0.2215\n",
      "Epoch 40/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0759 - mae: 0.2312 - val_loss: 0.0667 - val_mae: 0.2214\n",
      "Epoch 41/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0758 - mae: 0.2311 - val_loss: 0.0667 - val_mae: 0.2213\n",
      "Epoch 42/500\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0757 - mae: 0.2309 - val_loss: 0.0666 - val_mae: 0.2212\n",
      "Epoch 43/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0756 - mae: 0.2308 - val_loss: 0.0665 - val_mae: 0.2211\n",
      "Epoch 44/500\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0755 - mae: 0.2306 - val_loss: 0.0665 - val_mae: 0.2210\n",
      "Epoch 45/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0754 - mae: 0.2304 - val_loss: 0.0664 - val_mae: 0.2209\n",
      "Epoch 46/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0753 - mae: 0.2303 - val_loss: 0.0663 - val_mae: 0.2208\n",
      "Epoch 47/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0752 - mae: 0.2301 - val_loss: 0.0663 - val_mae: 0.2207\n",
      "Epoch 48/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0752 - mae: 0.2300 - val_loss: 0.0662 - val_mae: 0.2206\n",
      "Epoch 49/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0751 - mae: 0.2298 - val_loss: 0.0662 - val_mae: 0.2205\n",
      "Epoch 50/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0750 - mae: 0.2296 - val_loss: 0.0661 - val_mae: 0.2204\n",
      "Epoch 51/500\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0749 - mae: 0.2294 - val_loss: 0.0661 - val_mae: 0.2203\n",
      "Epoch 52/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0749 - mae: 0.2293 - val_loss: 0.0660 - val_mae: 0.2202\n",
      "Epoch 53/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0748 - mae: 0.2292 - val_loss: 0.0659 - val_mae: 0.2201\n",
      "Epoch 54/500\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0747 - mae: 0.2290 - val_loss: 0.0659 - val_mae: 0.2200\n",
      "Epoch 55/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0746 - mae: 0.2289 - val_loss: 0.0658 - val_mae: 0.2199\n",
      "Epoch 56/500\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0746 - mae: 0.2287 - val_loss: 0.0658 - val_mae: 0.2198\n",
      "Epoch 57/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0745 - mae: 0.2286 - val_loss: 0.0657 - val_mae: 0.2197\n",
      "Epoch 58/500\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0744 - mae: 0.2285 - val_loss: 0.0657 - val_mae: 0.2196\n",
      "Epoch 59/500\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0744 - mae: 0.2284 - val_loss: 0.0656 - val_mae: 0.2195\n",
      "Epoch 60/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0743 - mae: 0.2282 - val_loss: 0.0656 - val_mae: 0.2194\n",
      "Epoch 61/500\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0742 - mae: 0.2281 - val_loss: 0.0656 - val_mae: 0.2193\n",
      "Epoch 62/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0742 - mae: 0.2280 - val_loss: 0.0655 - val_mae: 0.2192\n",
      "Epoch 63/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0741 - mae: 0.2279 - val_loss: 0.0655 - val_mae: 0.2191\n",
      "Epoch 64/500\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0741 - mae: 0.2278 - val_loss: 0.0654 - val_mae: 0.2190\n",
      "Epoch 65/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0740 - mae: 0.2277 - val_loss: 0.0654 - val_mae: 0.2190\n",
      "Epoch 66/500\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.0739 - mae: 0.2275 - val_loss: 0.0654 - val_mae: 0.2189\n",
      "Epoch 67/500\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0739 - mae: 0.2275 - val_loss: 0.0653 - val_mae: 0.2188\n",
      "Epoch 68/500\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.0739 - mae: 0.2274 - val_loss: 0.0653 - val_mae: 0.2187\n",
      "Epoch 69/500\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.0738 - mae: 0.2273 - val_loss: 0.0653 - val_mae: 0.2187\n",
      "Epoch 70/500\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.0738 - mae: 0.2272 - val_loss: 0.0653 - val_mae: 0.2186\n",
      "Epoch 71/500\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.0738 - mae: 0.2271 - val_loss: 0.0652 - val_mae: 0.2185\n",
      "Epoch 72/500\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.0737 - mae: 0.2270 - val_loss: 0.0652 - val_mae: 0.2185\n",
      "Epoch 73/500\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.0737 - mae: 0.2270 - val_loss: 0.0652 - val_mae: 0.2184\n",
      "Epoch 74/500\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.0736 - mae: 0.2269 - val_loss: 0.0652 - val_mae: 0.2184\n",
      "Epoch 75/500\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.0736 - mae: 0.2268 - val_loss: 0.0651 - val_mae: 0.2183\n",
      "Epoch 76/500\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0736 - mae: 0.2267 - val_loss: 0.0651 - val_mae: 0.2182\n",
      "Epoch 77/500\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0735 - mae: 0.2267 - val_loss: 0.0651 - val_mae: 0.2182\n",
      "Epoch 78/500\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0735 - mae: 0.2266 - val_loss: 0.0651 - val_mae: 0.2181\n",
      "Epoch 79/500\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0735 - mae: 0.2266 - val_loss: 0.0650 - val_mae: 0.2180\n",
      "Epoch 80/500\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.0734 - mae: 0.2265 - val_loss: 0.0650 - val_mae: 0.2180\n",
      "Epoch 81/500\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0734 - mae: 0.2264 - val_loss: 0.0650 - val_mae: 0.2179\n",
      "Epoch 82/500\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.0734 - mae: 0.2264 - val_loss: 0.0650 - val_mae: 0.2178\n",
      "Epoch 83/500\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.0733 - mae: 0.2263 - val_loss: 0.0650 - val_mae: 0.2178\n",
      "Epoch 84/500\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.0733 - mae: 0.2262 - val_loss: 0.0649 - val_mae: 0.2177\n",
      "Epoch 85/500\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0733 - mae: 0.2262 - val_loss: 0.0649 - val_mae: 0.2177\n",
      "Epoch 86/500\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.0732 - mae: 0.2261 - val_loss: 0.0649 - val_mae: 0.2176\n",
      "Epoch 87/500\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.0732 - mae: 0.2261 - val_loss: 0.0649 - val_mae: 0.2176\n",
      "Epoch 88/500\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0732 - mae: 0.2260 - val_loss: 0.0649 - val_mae: 0.2175\n",
      "Epoch 89/500\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0732 - mae: 0.2260 - val_loss: 0.0649 - val_mae: 0.2175\n",
      "Epoch 90/500\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.0731 - mae: 0.2259 - val_loss: 0.0648 - val_mae: 0.2174\n",
      "Epoch 91/500\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0731 - mae: 0.2258 - val_loss: 0.0648 - val_mae: 0.2174\n",
      "Epoch 92/500\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.0731 - mae: 0.2258 - val_loss: 0.0648 - val_mae: 0.2173\n",
      "Epoch 93/500\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.0730 - mae: 0.2257 - val_loss: 0.0648 - val_mae: 0.2173\n",
      "Epoch 94/500\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0730 - mae: 0.2257 - val_loss: 0.0648 - val_mae: 0.2172\n",
      "Epoch 95/500\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.0730 - mae: 0.2256 - val_loss: 0.0648 - val_mae: 0.2172\n",
      "Epoch 96/500\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.0730 - mae: 0.2255 - val_loss: 0.0648 - val_mae: 0.2171\n",
      "Epoch 97/500\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0729 - mae: 0.2255 - val_loss: 0.0647 - val_mae: 0.2170\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x24e9b422b20>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_min_delta.fit(X, y,\n",
    "          epochs = 500,\n",
    "          validation_split=0.2,\n",
    "          callbacks=[earlyStopping_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid #E1F6FF\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='Orange'>Usage of Batch Size</font>\n",
    "\n",
    "<font size=\"3\">**<span style=\"background-color: #ECECEC; color:#0047bb\">.fit()</span> trains a model by slicing the data into \"batches\" of size <span style=\"color:#4285F4\">batch_size</span>, and repeatedly iterating over the entire dataset for a given number of <span style=\"color:#4285F4\">epochs</span>.**</font>\n",
    "\n",
    "<font size=\"3\">**There are three different types of <span style=\"color:#4285F4\">gradient descent</span>:**</font>\n",
    "\n",
    "><font size=\"3\">**<span style=\"color:#4285F4\">Stochastic Gradient Descent</span> is applied, if <span style=\"color:#4285F4\">batch_size</span> equals <span style=\"color:red\">1</span>**</font><br>\n",
    ">><font size=\"3\">**A single sample is randomly picked and used to compute the gradient of the cost function for each iteration of the gradient descent and then update the parameters.**</font>\n",
    "\n",
    "><font size=\"3\">**<span style=\"color:#4285F4\">Batch Gradient Descent or Vanilla Gradient Descent</span> is applied, if <span style=\"color:#4285F4\">batch_size</span> equals <span style=\"color:red\">total number of samples</span>**</font><br>\n",
    ">><font size=\"3\">**The entire dataset are used to compute the gradient of the cost function for each iteration of the gradient descent and then update the parameters.**</font>\n",
    "\n",
    "><font size=\"3\">**<span style=\"color:#4285F4\">Mini batch Gradient Descent</span> is applied, if <span style=\"color:#4285F4\">batch_size</span> is larger than <span style=\"color:red\">1</span> but less than <span style=\"color:red\">total number of samples</span>**</font><br>\n",
    ">><font size=\"3\">**A mini batch of samples is randomly picked and used to compute the gradient of the cost function for each iteration of the gradient descent and then update the parameters.**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">**If <span style=\"color:#4285F4\">batch_size</span> is <span style=\"color:#4285F4\">too small</span>, the model weights can be easily affected by small portion of data and it results in a less accurate estimate of the gradient. If <span style=\"color:#4285F4\">batch_size</span> is <span style=\"color:#4285F4\">too large</span>, it can cause out of memory issue, especially with very large datasets.**</font>\n",
    "\n",
    "<font size=\"3\">**For these reasons, smaller <span style=\"color:#4285F4\">batch_size</span> are often used. By default, Keras applies <span style=\"color:#4285F4\">Mini batch Gradient Descent</span> with <span style=\"color:#4285F4\">32 samples</span>.**</font>\n",
    "\n",
    "><font size=\"3\">**Smaller batch sizes are noisy, offering a regularizing effect and lower generalization error.**</font>\n",
    "\n",
    "><font size=\"3\">**Smaller batch sizes make it easier to fit one batch worth of training data in memory (i.e. when using a GPU).**</font>\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5 Sequential Model - Evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">**To evaluate the <span style=\"color:#4285F4\">generalisability</span> of a final model, it is always important to use the data that the model was not trained on, namely <span style=\"color:#4285F4\">testing data</span>.**</font>\n",
    "\n",
    "<font size=\"3\">**A simple way to split all the samples into two datasets:**</font>\n",
    "\n",
    "><font size=\"3\">**Training dataset & Validation dataset** - The argument of <span style=\"color:#4285F4\">validation_split</span> or <span style=\"color:#4285F4\">validation_data</span> from <span style=\"background-color: #ECECEC; color:#0047bb\">.fit()</span> can be used to split the samples into <span style=\"color:#4285F4\">training and validataion dataset</span>.</font>\n",
    "\n",
    "><font size=\"3\">**Testing dataset** - Once a model is <span style=\"color:#4285F4\">completely trained</span>, <span style=\"color:#4285F4\">unseen data</span> in testing dataset can be used to evaluate how well or how bad a model perform. This provides an <span style=\"color:#4285F4\">unbiased evaluation</span> and is always considered as a <span style=\"color:#4285F4\">good practice</span>.</font>\n",
    "\n",
    "<img src=\"https://firebasestorage.googleapis.com/v0/b/deep-learning-crash-course.appspot.com/o/4NNEvaluate.png?alt=media&token=e4701b4b-11b2-48e9-8591-d67fd4cdcc13\" width=\"1000\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">**In the final model, <span style=\"background-color: #ECECEC; color:#0047bb\">.evaluate()</span> returns the <span style=\"color:#4285F4\">loss value</span> and <span style=\"color:#4285F4\">metrics values</span> according to arguments provided in <span style=\"background-color: #ECECEC; color:#0047bb\">.compile()</span>.**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='#176BEF'> Examples </font>\n",
    "<hr style=\"border:2px solid #E1F6FF\"> </hr>\n",
    "<img src=\"https://firebasestorage.googleapis.com/v0/b/deep-learning-crash-course.appspot.com/o/3NN9.png?alt=media&token=664be587-f0fe-43ec-8217-5ca7779ca0dd\" width=\"100\" align=\"right\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.random((100, 3))\n",
    "y = np.random.random((100, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">**Split the 100 samples into two datasets**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training & Validation Dataset: (90, 3) (90, 1)\n",
      "Test Dataset: (10, 3) (10, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=123)\n",
    "\n",
    "print('Training & Validation Dataset:', X_train.shape, y_train.shape)\n",
    "print('Test Dataset:', X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(2, activation='relu', input_shape=(3,)))\n",
    "model.add(Dense(1, activation ='sigmoid'))\n",
    "model.compile(optimizer=\"adam\", loss=\"mse\", metrics=\"mae\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">**Split the 90 samples into training and validation dataset**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.1319 - mae: 0.2946 - val_loss: 0.1614 - val_mae: 0.3490\n",
      "Epoch 2/5\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1302 - mae: 0.2925 - val_loss: 0.1595 - val_mae: 0.3469\n",
      "Epoch 3/5\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.1286 - mae: 0.2906 - val_loss: 0.1576 - val_mae: 0.3447\n",
      "Epoch 4/5\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1269 - mae: 0.2883 - val_loss: 0.1558 - val_mae: 0.3425\n",
      "Epoch 5/5\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.1254 - mae: 0.2863 - val_loss: 0.1539 - val_mae: 0.3404\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x24e9d2a4730>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train,\n",
    "          validation_split=0.2,\n",
    "          epochs = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">**Evaluate the final model with test dataset**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2611 - mae: 0.4374\n",
      "Test Loss - MSE: 0.2611391842365265\n",
      "Test Metrics - MAE: 0.4374386668205261\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_metrics = model.evaluate(X_test, y_test)\n",
    "\n",
    "print('Test Loss - MSE:', test_loss)\n",
    "print('Test Metrics - MAE:', test_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid #E1F6FF\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.6 Sequential Model - Predict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">**Once the model is created, <span style=\"background-color: #ECECEC; color:#0047bb\">.predict()</span> can be used to do prediction.**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='#176BEF'> Examples </font>\n",
    "<hr style=\"border:2px solid #E1F6FF\"> </hr>\n",
    "<img src=\"https://firebasestorage.googleapis.com/v0/b/deep-learning-crash-course.appspot.com/o/3NN9.png?alt=media&token=664be587-f0fe-43ec-8217-5ca7779ca0dd\" width=\"100\" align=\"right\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0764 - mae: 0.2371\n",
      "Epoch 2/5\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0763 - mae: 0.2369\n",
      "Epoch 3/5\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0761 - mae: 0.2367\n",
      "Epoch 4/5\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0761 - mae: 0.2366\n",
      "Epoch 5/5\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0760 - mae: 0.2364\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x24e9e6a03d0>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.random.random((100, 3))\n",
    "y = np.random.random((100, 1))\n",
    "\n",
    "model=Sequential()\n",
    "model.add(Dense(2, activation='relu', input_shape=(3,)))\n",
    "model.add(Dense(1, activation ='sigmoid'))\n",
    "model.compile(optimizer=\"adam\", loss=\"mse\", metrics=\"mae\")\n",
    "\n",
    "model.fit(X, y,\n",
    "          epochs = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">**<span style=\"color:#4285F4\">Same number of features</span> is needed in order to generate prediction.**</font>\n",
    "\n",
    "<font size=\"3\">**In this example, 3 features have been used for training. So 3 features are needed for prediction.**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prediction is: [[0.46480438]]\n"
     ]
    }
   ],
   "source": [
    "prediction_single = model.predict(np.random.random((1, 3)))\n",
    "\n",
    "print(\"The prediction is:\", prediction_single)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prediction is: [[0.45315924]\n",
      " [0.41939664]\n",
      " [0.47458243]\n",
      " [0.4812256 ]\n",
      " [0.46150655]\n",
      " [0.47832948]\n",
      " [0.44983304]\n",
      " [0.49562877]\n",
      " [0.44853142]\n",
      " [0.4879438 ]]\n"
     ]
    }
   ],
   "source": [
    "prediction_batch = model.predict(np.random.random((10, 3)))\n",
    "\n",
    "print(\"The prediction is:\", prediction_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid #E1F6FF\"> </hr>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
